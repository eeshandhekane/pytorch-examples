{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty tensor: tensor([[[ 1.2416e-29,  1.4013e-45],\n",
      "         [ 4.9045e-44,  1.4013e-45],\n",
      "         [ 0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.1704e-41]],\n",
      "\n",
      "        [[ 0.0000e+00,  2.2369e+08],\n",
      "         [ 0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00],\n",
      "         [        nan,         nan]],\n",
      "\n",
      "        [[ 1.9933e-32,         nan],\n",
      "         [ 2.2369e+08,  2.2369e+08],\n",
      "         [-2.2439e+32,  4.5782e-41],\n",
      "         [ 0.0000e+00,  0.0000e+00]]])\n",
      "empty tensor type: torch.float32\n",
      "empty tensor shape: torch.Size([3, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# Create an uninitialized tensor, which has garbage and datatype float32.\n",
    "x = torch.empty(size=(3, 4, 2))  # torch.empty(3, 4, 2). Also, torch.Tensor(3, 4, 2) works!\n",
    "print('empty tensor: {}'.format(x))\n",
    "print('empty tensor type: {}'.format(x.dtype))\n",
    "print('empty tensor shape: {}'.format(x.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ones tensor: tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n",
      "all ones tensor type: torch.float32\n",
      "all ones tensor shape: torch.Size([3, 4, 2])\n",
      "all zeros tensor: tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "all zeros tensor type: torch.float32\n",
      "all zeros tensor shape: torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of all ones. Analogously, torch.zeros works too.\n",
    "ones = torch.ones(size=(3, 4, 2))\n",
    "print('all ones tensor: {}'.format(ones))\n",
    "print('all ones tensor type: {}'.format(ones.dtype))\n",
    "print('all ones tensor shape: {}'.format(ones.shape))\n",
    "zeros = torch.zeros(4, 2, 3)\n",
    "print('all zeros tensor: {}'.format(zeros))\n",
    "print('all zeros tensor type: {}'.format(zeros.dtype))\n",
    "print('all zeros tensor shape: {}'.format(zeros.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random tensor: tensor([[[0.5349, 0.1988],\n",
      "         [0.6592, 0.6569],\n",
      "         [0.2328, 0.4251],\n",
      "         [0.2071, 0.6297]],\n",
      "\n",
      "        [[0.3653, 0.8513],\n",
      "         [0.8549, 0.5509],\n",
      "         [0.2868, 0.2063],\n",
      "         [0.4451, 0.3593]],\n",
      "\n",
      "        [[0.7204, 0.0731],\n",
      "         [0.9699, 0.1078],\n",
      "         [0.8829, 0.4132],\n",
      "         [0.7572, 0.6948]]])\n",
      "random tensor type: torch.float32\n",
      "random tensor shape: torch.Size([3, 4, 2])\n",
      "random tensor: tensor([[[0.5349, 0.1988],\n",
      "         [0.6592, 0.6569],\n",
      "         [0.2328, 0.4251],\n",
      "         [0.2071, 0.6297]],\n",
      "\n",
      "        [[0.3653, 0.8513],\n",
      "         [0.8549, 0.5509],\n",
      "         [0.2868, 0.2063],\n",
      "         [0.4451, 0.3593]],\n",
      "\n",
      "        [[0.7204, 0.0731],\n",
      "         [0.9699, 0.1078],\n",
      "         [0.8829, 0.4132],\n",
      "         [0.7572, 0.6948]]])\n",
      "random tensor type: torch.float32\n",
      "random tensor shape: torch.Size([3, 4, 2])\n",
      "both tensor values are the same: True\n"
     ]
    }
   ],
   "source": [
    "# Random floats from [0.0, 1.0) range.\n",
    "torch.manual_seed(seed=7)\n",
    "x = torch.rand(size=(3, 4, 2))\n",
    "print('random tensor: {}'.format(x))\n",
    "print('random tensor type: {}'.format(x.dtype))\n",
    "print('random tensor shape: {}'.format(x.shape))\n",
    "torch.manual_seed(seed=7)\n",
    "x_again = torch.rand(size=(3, 4, 2))\n",
    "print('random tensor: {}'.format(x))\n",
    "print('random tensor type: {}'.format(x.dtype))\n",
    "print('random tensor shape: {}'.format(x.shape))  # Identical results with manual seed.\n",
    "# noinspection PyTypeChecker\n",
    "print('both tensor values are the same: {}'.format(torch.all(x==x_again)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random integer tensor: tensor([[5, 2, 1, 6],\n",
      "        [3, 7, 7, 9],\n",
      "        [8, 1, 8, 1]])\n",
      "random integer tensor type: torch.int64\n",
      "random integer tensor shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Random ranged integers.\n",
    "torch.manual_seed(seed=7)\n",
    "x = torch.randint(low=0, high=10, size=(3, 4))\n",
    "print('random integer tensor: {}'.format(x))\n",
    "print('random integer tensor type: {}'.format(x.dtype))\n",
    "print('random integer tensor shape: {}'.format(x.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "x: tensor([[[0.5349, 0.1988, 0.6592, 0.6569],\n",
      "         [0.2328, 0.4251, 0.2071, 0.6297]],\n",
      "\n",
      "        [[0.3653, 0.8513, 0.8549, 0.5509],\n",
      "         [0.2868, 0.2063, 0.4451, 0.3593]],\n",
      "\n",
      "        [[0.7204, 0.0731, 0.9699, 0.1078],\n",
      "         [0.8829, 0.4132, 0.7572, 0.6948]]])\n",
      "*******************************************************************************\n",
      "empty tensor like x: tensor([[[0.5349, 0.1988, 0.6592, 0.6569],\n",
      "         [0.2328, 0.4251, 0.2071, 0.6297]],\n",
      "\n",
      "        [[0.3653, 0.8513, 0.8549, 0.5509],\n",
      "         [0.2868, 0.2063, 0.4451, 0.3593]],\n",
      "\n",
      "        [[0.7204, 0.0731, 0.9699, 0.1078],\n",
      "         [0.8829, 0.4132, 0.7572, 0.6948]]])\n",
      "empty tensor type like x: torch.float32\n",
      "empty tensor shape like x: torch.Size([3, 2, 4])\n",
      "*******************************************************************************\n",
      "all ones tensor like x: tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "all ones tensor type like x: torch.float32\n",
      "all ones tensor shape like x: torch.Size([3, 2, 4])\n",
      "*******************************************************************************\n",
      "all zeros tensor like x: tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "all zeros tensor type like x: torch.float32\n",
      "all zeros tensor shape like x: torch.Size([3, 2, 4])\n",
      "*******************************************************************************\n",
      "random tensor like x: tensor([[[0.5209, 0.5932, 0.8797, 0.6286],\n",
      "         [0.7653, 0.1132, 0.8559, 0.6721]],\n",
      "\n",
      "        [[0.6267, 0.5691, 0.7437, 0.9592],\n",
      "         [0.3887, 0.2214, 0.3742, 0.1953]],\n",
      "\n",
      "        [[0.7405, 0.2529, 0.2332, 0.9314],\n",
      "         [0.9575, 0.5575, 0.4134, 0.4355]]])\n",
      "random tensor type like x: torch.float32\n",
      "random tensor shape like x: torch.Size([3, 2, 4])\n",
      "*******************************************************************************\n",
      "random integer tensor like x: tensor([[[2., 2., 9., 9.],\n",
      "         [7., 3., 0., 7.]],\n",
      "\n",
      "        [[0., 5., 2., 2.],\n",
      "         [0., 7., 3., 2.]],\n",
      "\n",
      "        [[0., 0., 3., 9.],\n",
      "         [2., 9., 1., 2.]]])\n",
      "random integer tensor like x type: torch.float32\n",
      "random integer tensor like x shape: torch.Size([3, 2, 4])\n",
      "*******************************************************************************\n",
      "random integer tensor like x: tensor([[[1, 5, 7, 2],\n",
      "         [5, 6, 3, 8]],\n",
      "\n",
      "        [[1, 1, 1, 5],\n",
      "         [1, 9, 9, 7]],\n",
      "\n",
      "        [[6, 9, 9, 3],\n",
      "         [8, 3, 7, 3]]], dtype=torch.int32)\n",
      "random integer tensor like x type : torch.int32\n",
      "random integer tensor like x shape: torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Create tensors of the same shape.\n",
    "torch.manual_seed(seed=7)\n",
    "x = torch.rand(size=(3, 2, 4))\n",
    "print('*'*79)\n",
    "print('x: {}'.format(x))\n",
    "x_empty = torch.empty_like(x)\n",
    "print('*'*79)\n",
    "print('empty tensor like x: {}'.format(x_empty))\n",
    "print('empty tensor type like x: {}'.format(x_empty.dtype))\n",
    "print('empty tensor shape like x: {}'.format(x_empty.shape))\n",
    "x_ones = torch.ones_like(x)\n",
    "print('*'*79)\n",
    "print('all ones tensor like x: {}'.format(x_ones))\n",
    "print('all ones tensor type like x: {}'.format(x_ones.dtype))\n",
    "print('all ones tensor shape like x: {}'.format(x_ones.shape))\n",
    "x_zeros = torch.zeros_like(x)\n",
    "print('*'*79)\n",
    "print('all zeros tensor like x: {}'.format(x_zeros))\n",
    "print('all zeros tensor type like x: {}'.format(x_zeros.dtype))\n",
    "print('all zeros tensor shape like x: {}'.format(x_zeros.shape))\n",
    "x_rand = torch.rand_like(x)\n",
    "print('*'*79)\n",
    "print('random tensor like x: {}'.format(x_rand))\n",
    "print('random tensor type like x: {}'.format(x_rand.dtype))\n",
    "print('random tensor shape like x: {}'.format(x_rand.shape))\n",
    "x_randint = torch.randint_like(input=x, low=0, high=10)  # The data type is cast to that of x, which is float32!\n",
    "print('*'*79)\n",
    "print('random integer tensor like x: {}'.format(x_randint))\n",
    "print('random integer tensor like x type: {}'.format(x_randint.dtype))\n",
    "print('random integer tensor like x shape: {}'.format(x_randint.shape))\n",
    "x_randint = torch.randint_like(input=x, low=0, high=10, dtype=torch.int32)\n",
    "print('*'*79)\n",
    "print('random integer tensor like x: {}'.format(x_randint))\n",
    "print('random integer tensor like x type : {}'.format(x_randint.dtype))\n",
    "print('random integer tensor like x shape: {}'.format(x_randint.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x from data: tensor([[[ 1.,  2.,  3.],\n",
      "         [ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 5.,  6.,  7.],\n",
      "         [ 7.,  8.,  9.]],\n",
      "\n",
      "        [[10., 11., 12.],\n",
      "         [13., 14., 15.]],\n",
      "\n",
      "        [[16., 17., 18.],\n",
      "         [19., 20., 21.]]])\n",
      "x from data type: torch.float32\n",
      "x from data shape: torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor from the data given.\n",
    "# The tensor stores its own copy of the data.\n",
    "# Note different containers used (lists and tuples).\n",
    "x = torch.tensor(\n",
    "    data=(\n",
    "        ([1, 2, 3], (3, 4, 5)),\n",
    "        ([5, 6, 7], (7, 8, 9)),\n",
    "        [[10, 11, 12], [13, 14, 15]],\n",
    "        ((16, 17, 18), (19, 20, 21))\n",
    "    ), dtype=torch.float32\n",
    ")\n",
    "print('x from data: {}'.format(x))\n",
    "print('x from data type: {}'.format(x.dtype))\n",
    "print('x from data shape: {}'.format(x.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[0.1956, 0.8861, 0.7264, 0.8868],\n",
      "        [0.1278, 0.0125, 0.1721, 0.5535],\n",
      "        [0.4012, 0.1849, 0.8640, 0.3388]]), type: torch.float32\n",
      "x: tensor([[2., 9., 0., 0.],\n",
      "        [3., 5., 5., 7.],\n",
      "        [0., 9., 4., 8.]]), type: torch.float32\n",
      "x: tensor([[2, 8, 1, 6],\n",
      "        [9, 9, 3, 0],\n",
      "        [8, 5, 0, 4]], dtype=torch.int32), type: torch.int32\n",
      "x: tensor([[0.0326, 0.7688, 0.9323, 0.6635],\n",
      "        [0.1906, 0.7637, 0.9149, 0.3977],\n",
      "        [0.4180, 0.6731, 0.5643, 0.3347]]), type: torch.float32\n",
      "x: tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]], dtype=torch.int32), type: torch.int32\n",
      "x: tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]]), type: torch.bool\n",
      "x: tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]]), type: torch.bool\n",
      "x: tensor([[[False, False],\n",
      "         [ True,  True],\n",
      "         [ True,  True],\n",
      "         [False, False]],\n",
      "\n",
      "        [[ True, False],\n",
      "         [False, False],\n",
      "         [ True,  True],\n",
      "         [ True,  True]],\n",
      "\n",
      "        [[ True, False],\n",
      "         [ True, False],\n",
      "         [ True,  True],\n",
      "         [False, False]]]), type: torch.bool\n",
      "*******************************************************************************\n",
      "x: tensor([[1, 5, 1, 6],\n",
      "        [9, 2, 0, 5],\n",
      "        [9, 7, 7, 4]]), type: torch.int64\n",
      "*******************************************************************************\n",
      "x_int: tensor([[1, 5, 1, 6],\n",
      "        [9, 2, 0, 5],\n",
      "        [9, 7, 7, 4]], dtype=torch.int32), type: torch.int32\n",
      "x_int8: tensor([[1, 5, 1, 6],\n",
      "        [9, 2, 0, 5],\n",
      "        [9, 7, 7, 4]], dtype=torch.int8), type: torch.int8\n",
      "x_int16: tensor([[1, 5, 1, 6],\n",
      "        [9, 2, 0, 5],\n",
      "        [9, 7, 7, 4]], dtype=torch.int16), type: torch.int16\n",
      "x_int32: tensor([[1, 5, 1, 6],\n",
      "        [9, 2, 0, 5],\n",
      "        [9, 7, 7, 4]], dtype=torch.int32), type: torch.int32\n",
      "x_int64: tensor([[1, 5, 1, 6],\n",
      "        [9, 2, 0, 5],\n",
      "        [9, 7, 7, 4]]), type: torch.int64\n",
      "*******************************************************************************\n",
      "x_float: tensor([[1., 5., 1., 6.],\n",
      "        [9., 2., 0., 5.],\n",
      "        [9., 7., 7., 4.]]), type: torch.float32\n",
      "x_float16: tensor([[1., 5., 1., 6.],\n",
      "        [9., 2., 0., 5.],\n",
      "        [9., 7., 7., 4.]], dtype=torch.float16), type: torch.float16\n",
      "x_float32: tensor([[1., 5., 1., 6.],\n",
      "        [9., 2., 0., 5.],\n",
      "        [9., 7., 7., 4.]]), type: torch.float32\n",
      "x_float64: tensor([[1., 5., 1., 6.],\n",
      "        [9., 2., 0., 5.],\n",
      "        [9., 7., 7., 4.]], dtype=torch.float64), type: torch.float64\n",
      "*******************************************************************************\n",
      "x_bool: tensor([[ True,  True,  True,  True],\n",
      "        [ True,  True, False,  True],\n",
      "        [ True,  True,  True,  True]]), type: torch.bool\n",
      "*******************************************************************************\n",
      "x_uint8: tensor([[1, 5, 1, 6],\n",
      "        [9, 2, 0, 5],\n",
      "        [9, 7, 7, 4]], dtype=torch.uint8), type: torch.uint8\n"
     ]
    }
   ],
   "source": [
    "# Data types by specifying the `dtype` parameter.\n",
    "x = torch.rand(size=(3, 4), dtype=torch.float)  # floatX works, intX doesn't!\n",
    "print('x: {}, type: {}'.format(x, x.dtype))\n",
    "x = torch.randint(low=0, high=10, size=(3, 4), dtype=torch.float32)  # intX and floatX work!\n",
    "print('x: {}, type: {}'.format(x, x.dtype))\n",
    "x = torch.randint(low=0, high=10, size=(3, 4), dtype=torch.int)  # intX and floatX work!\n",
    "print('x: {}, type: {}'.format(x, x.dtype))\n",
    "# Data type by casting via attributes float(), int(), bool().\n",
    "x = torch.rand(size=(3, 4)).float()  # Casts to float32.\n",
    "print('x: {}, type: {}'.format(x, x.dtype))\n",
    "x = torch.rand(size=(3, 4)).int()  # Casts to int32. So, it will all be zero! (why?)\n",
    "print('x: {}, type: {}'.format(x, x.dtype))\n",
    "x = torch.rand(size=(3, 4)).bool()  # Casts to bool. So, it will all be True! (why?)\n",
    "print('x: {}, type: {}'.format(x, x.dtype))\n",
    "x = torch.rand(size=(3, 4)).int().bool()  # Casts to int32 and then to bool. So, it will all be False! (why?)\n",
    "print('x: {}, type: {}'.format(x, x.dtype))\n",
    "# Creating a random bool tensor of `True` and `False` values.\n",
    "x = torch.randint(low=0, high=2, size=(3, 4, 2), dtype=torch.bool)\n",
    "print('x: {}, type: {}'.format(x, x.dtype))\n",
    "# Casting with the `.to(<...>)` attribute.\n",
    "x = torch.randint(low=0, high=10, size=(3, 4))\n",
    "print('*'*79)\n",
    "print('x: {}, type: {}'.format(x, x.dtype))\n",
    "print('*'*79)\n",
    "x_int = x.to(torch.int)\n",
    "print('x_int: {}, type: {}'.format(x_int, x_int.dtype))\n",
    "x_int8 = x.to(torch.int8)\n",
    "print('x_int8: {}, type: {}'.format(x_int8, x_int8.dtype))\n",
    "x_int16 = x.to(torch.int16)\n",
    "print('x_int16: {}, type: {}'.format(x_int16, x_int16.dtype))\n",
    "x_int32 = x.to(torch.int32)\n",
    "print('x_int32: {}, type: {}'.format(x_int32, x_int32.dtype))\n",
    "x_int64 = x.to(torch.int64)\n",
    "print('x_int64: {}, type: {}'.format(x_int64, x_int64.dtype))\n",
    "print('*'*79)\n",
    "x_float = x.to(torch.float)\n",
    "print('x_float: {}, type: {}'.format(x_float, x_float.dtype))\n",
    "x_float16 = x.to(torch.float16)  # float8 does not exist!\n",
    "print('x_float16: {}, type: {}'.format(x_float16, x_float16.dtype))\n",
    "x_float32 = x.to(torch.float32)\n",
    "print('x_float32: {}, type: {}'.format(x_float32, x_float32.dtype))\n",
    "x_float64 = x.to(torch.float64)\n",
    "print('x_float64: {}, type: {}'.format(x_float64, x_float64.dtype))\n",
    "print('*'*79)\n",
    "x_bool = x.to(torch.bool)\n",
    "print('x_bool: {}, type: {}'.format(x_bool, x_bool.dtype))\n",
    "print('*'*79)\n",
    "x_uint8 = x.to(torch.uint8)\n",
    "print('x_uint8: {}, type: {}'.format(x_uint8, x_uint8.dtype))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Result 1\n",
      "tensor([[5, 2, 1],\n",
      "        [6, 3, 7]]) \n",
      "+\n",
      " tensor([[7, 9, 8],\n",
      "        [1, 8, 1]]) \n",
      "=\n",
      " tensor([[12, 11,  9],\n",
      "        [ 7, 11,  8]])\n",
      "########## Result 2\n",
      "tensor([[[5, 2, 1],\n",
      "         [6, 3, 7]],\n",
      "\n",
      "        [[7, 9, 8],\n",
      "         [1, 8, 1]]]) \n",
      "+\n",
      " tensor([8, 7, 2]) \n",
      "=\n",
      " tensor([[[13,  9,  3],\n",
      "         [14, 10,  9]],\n",
      "\n",
      "        [[15, 16, 10],\n",
      "         [ 9, 15,  3]]])\n",
      "########## Result 3\n",
      "tensor([[[5, 2, 1],\n",
      "         [6, 3, 7]],\n",
      "\n",
      "        [[7, 9, 8],\n",
      "         [1, 8, 1]]]) \n",
      "+\n",
      " tensor([[8, 7, 2]]) \n",
      "=\n",
      " tensor([[[13,  9,  3],\n",
      "         [14, 10,  9]],\n",
      "\n",
      "        [[15, 16, 10],\n",
      "         [ 9, 15,  3]]])\n",
      "########## Result 4\n",
      "tensor([[[5, 2, 1],\n",
      "         [6, 3, 7]],\n",
      "\n",
      "        [[7, 9, 8],\n",
      "         [1, 8, 1]]]) \n",
      "+\n",
      " tensor([[[8, 7, 2]]]) \n",
      "=\n",
      " tensor([[[13,  9,  3],\n",
      "         [14, 10,  9]],\n",
      "\n",
      "        [[15, 16, 10],\n",
      "         [ 9, 15,  3]]])\n",
      "########## Result 5\n",
      "tensor([[[5, 2, 1],\n",
      "         [6, 3, 7]],\n",
      "\n",
      "        [[7, 9, 8],\n",
      "         [1, 8, 1]]]) \n",
      "+\n",
      " tensor([[8, 7, 2],\n",
      "        [0, 6, 2]]) \n",
      "=\n",
      " tensor([[[13,  9,  3],\n",
      "         [ 6,  9,  9]],\n",
      "\n",
      "        [[15, 16, 10],\n",
      "         [ 1, 14,  3]]])\n",
      "########## Result 6\n",
      "tensor([[[5, 2, 1],\n",
      "         [6, 3, 7]],\n",
      "\n",
      "        [[7, 9, 8],\n",
      "         [1, 8, 1]]]) \n",
      "+\n",
      " tensor([[[8, 7, 2],\n",
      "         [0, 6, 2]]]) \n",
      "=\n",
      " tensor([[[13,  9,  3],\n",
      "         [ 6,  9,  9]],\n",
      "\n",
      "        [[15, 16, 10],\n",
      "         [ 1, 14,  3]]])\n",
      "########## Result 7\n",
      "tensor([[[5, 2, 1],\n",
      "         [6, 3, 7]],\n",
      "\n",
      "        [[7, 9, 8],\n",
      "         [1, 8, 1]]]) \n",
      "+\n",
      " tensor([[[8],\n",
      "         [7]]]) \n",
      "=\n",
      " tensor([[[13, 10,  9],\n",
      "         [13, 10, 14]],\n",
      "\n",
      "        [[15, 17, 16],\n",
      "         [ 8, 15,  8]]])\n",
      "########## Result 8\n",
      "tensor([[[5, 2, 1],\n",
      "         [6, 3, 7]],\n",
      "\n",
      "        [[7, 9, 8],\n",
      "         [1, 8, 1]]]) \n",
      "+\n",
      " tensor([[8],\n",
      "        [7]]) \n",
      "=\n",
      " tensor([[[13, 10,  9],\n",
      "         [13, 10, 14]],\n",
      "\n",
      "        [[15, 17, 16],\n",
      "         [ 8, 15,  8]]])\n",
      "########## Result 9\n",
      "tensor([[[5, 2, 1],\n",
      "         [6, 3, 7]],\n",
      "\n",
      "        [[7, 9, 8],\n",
      "         [1, 8, 1]]]) \n",
      "+\n",
      " tensor([[[8]],\n",
      "\n",
      "        [[7]]]) \n",
      "=\n",
      " tensor([[[13, 10,  9],\n",
      "         [14, 11, 15]],\n",
      "\n",
      "        [[14, 16, 15],\n",
      "         [ 8, 15,  8]]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor broadcasting with addition as example. Works for other ops too!\n",
    "torch.manual_seed(seed=7)\n",
    "x1 = torch.randint(low=0, high=10, size=[2, 3])\n",
    "x2 = torch.randint(low=0, high=10, size=[2, 3])\n",
    "ans1 = x1 + x2\n",
    "print('########## Result 1')\n",
    "print(x1, '\\n+\\n', x2, '\\n=\\n', ans1)\n",
    "\n",
    "# The three results below (2, 3, 4) must match.\n",
    "torch.manual_seed(seed=7)\n",
    "x1 = torch.randint(low=0, high=10, size=[2, 2, 3])\n",
    "x2 = torch.randint(low=0, high=10, size=[3, ])\n",
    "ans2 = x1 + x2\n",
    "print('########## Result 2')\n",
    "print(x1, '\\n+\\n', x2, '\\n=\\n', ans2)\n",
    "\n",
    "torch.manual_seed(seed=7)\n",
    "x1 = torch.randint(low=0, high=10, size=[2, 2, 3])\n",
    "x2 = torch.randint(low=0, high=10, size=[1, 3])\n",
    "ans3 = x1 + x2\n",
    "print('########## Result 3')\n",
    "print(x1, '\\n+\\n', x2, '\\n=\\n', ans3)\n",
    "\n",
    "torch.manual_seed(seed=7)\n",
    "x1 = torch.randint(low=0, high=10, size=[2, 2, 3])\n",
    "x2 = torch.randint(low=0, high=10, size=[1, 1, 3])\n",
    "ans4 = x1 + x2\n",
    "print('########## Result 4')\n",
    "print(x1, '\\n+\\n', x2, '\\n=\\n', ans4)\n",
    "\n",
    "# The two results below (5, 6) must match.\n",
    "torch.manual_seed(seed=7)\n",
    "x1 = torch.randint(low=0, high=10, size=[2, 2, 3])\n",
    "x2 = torch.randint(low=0, high=10, size=[2, 3])\n",
    "ans5 = x1 + x2\n",
    "print('########## Result 5')\n",
    "print(x1, '\\n+\\n', x2, '\\n=\\n', ans5)\n",
    "\n",
    "torch.manual_seed(seed=7)\n",
    "x1 = torch.randint(low=0, high=10, size=[2, 2, 3])\n",
    "x2 = torch.randint(low=0, high=10, size=[1, 2, 3])\n",
    "ans6 = x1 + x2\n",
    "print('########## Result 6')\n",
    "print(x1, '\\n+\\n', x2, '\\n=\\n', ans6)\n",
    "\n",
    "# The two results below (7, 8) must match.\n",
    "torch.manual_seed(seed=7)\n",
    "x1 = torch.randint(low=0, high=10, size=[2, 2, 3])\n",
    "x2 = torch.randint(low=0, high=10, size=[1, 2, 1])\n",
    "ans7 = x1 + x2\n",
    "print('########## Result 7')\n",
    "print(x1, '\\n+\\n', x2, '\\n=\\n', ans7)\n",
    "\n",
    "torch.manual_seed(seed=7)\n",
    "x1 = torch.randint(low=0, high=10, size=[2, 2, 3])\n",
    "x2 = torch.randint(low=0, high=10, size=[2, 1])\n",
    "ans8 = x1 + x2\n",
    "print('########## Result 8')\n",
    "print(x1, '\\n+\\n', x2, '\\n=\\n', ans8)\n",
    "\n",
    "torch.manual_seed(seed=7)\n",
    "x1 = torch.randint(low=0, high=10, size=[2, 2, 3])\n",
    "x2 = torch.randint(low=0, high=10, size=[2, 1, 1])\n",
    "ans9 = x1 + x2\n",
    "print('########## Result 9')\n",
    "print(x1, '\\n+\\n', x2, '\\n=\\n', ans9)\n",
    "\n",
    "# torch.manual_seed(seed=7)\n",
    "# x1 = torch.randint(low=0, high=10, size=[2, 2, 3])\n",
    "# x2 = torch.randint(low=0, high=10, size=[2, ])\n",
    "# print('########## Result 10')\n",
    "# print(x1, '\\n+\\n', x2, '\\n=\\n', x1+x2)  # This should produce an error.\n",
    "\n",
    "# torch.manual_seed(seed=7)\n",
    "# x1 = torch.randint(low=0, high=10, size=[2, 2, 4])\n",
    "# x2 = torch.randint(low=0, high=10, size=[1, 1, 2])\n",
    "# print('########## Result 11')\n",
    "# print(x1, '\\n+\\n', x2, '\\n=\\n', x1+x2)  # This should produce an error.\n",
    "\n",
    "# torch.manual_seed(seed=7)\n",
    "# x1 = torch.randint(low=0, high=10, size=[2, 2, 3])\n",
    "# x2 = torch.randint(low=0, high=10, size=[2, ])\n",
    "# print('########## Result 12')\n",
    "# print(x1, '\\n+\\n', x2, '\\n=\\n', x1+x2)  # This should produce an error.\n",
    "\n",
    "# noinspection PyTypeChecker\n",
    "assert (torch.all(ans2==ans3) and torch.all(ans2==ans4))\n",
    "# noinspection PyTypeChecker\n",
    "assert torch.all(ans5==ans6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[4.4509, 3.5929, 7.2038, 0.7305],\n",
      "        [9.6992, 1.0779, 8.8288, 4.1317],\n",
      "        [7.5719, 6.9485, 5.2093, 5.9323]])\n",
      "abs(x): tensor([[4.4509, 3.5929, 7.2038, 0.7305],\n",
      "        [9.6992, 1.0779, 8.8288, 4.1317],\n",
      "        [7.5719, 6.9485, 5.2093, 5.9323]])\n",
      "floor(x): tensor([[4., 3., 7., 0.],\n",
      "        [9., 1., 8., 4.],\n",
      "        [7., 6., 5., 5.]])\n",
      "ceil(x): tensor([[ 5.,  4.,  8.,  1.],\n",
      "        [10.,  2.,  9.,  5.],\n",
      "        [ 8.,  7.,  6.,  6.]])\n",
      "x_clamp_bet_3_and_7(x): tensor([[4.4509, 3.5929, 7.0000, 3.0000],\n",
      "        [7.0000, 3.0000, 7.0000, 4.1317],\n",
      "        [7.0000, 6.9485, 5.2093, 5.9323]])\n",
      "x_clamp_below_by_3(x): tensor([[4.4509, 3.5929, 7.2038, 3.0000],\n",
      "        [9.6992, 3.0000, 8.8288, 4.1317],\n",
      "        [7.5719, 6.9485, 5.2093, 5.9323]])\n",
      "x_clamp_above_by_7(x): tensor([[4.4509, 3.5929, 7.0000, 0.7305],\n",
      "        [7.0000, 1.0779, 7.0000, 4.1317],\n",
      "        [7.0000, 6.9485, 5.2093, 5.9323]])\n"
     ]
    }
   ],
   "source": [
    "# Some math operations.\n",
    "x = torch.rand(size=(3, 4))*10  # [0, 10) ranged random floats.\n",
    "print('x: {}'.format(x))\n",
    "x_abs = torch.abs(x)\n",
    "print('abs(x): {}'.format(x_abs))\n",
    "x_floor = torch.floor(x)\n",
    "print('floor(x): {}'.format(x_floor))\n",
    "x_ceil = torch.ceil(x)\n",
    "print('ceil(x): {}'.format(x_ceil))\n",
    "x_clamp_bet_3_and_7 = torch.clamp(x, min=3, max=7)\n",
    "print('x_clamp_bet_3_and_7(x): {}'.format(x_clamp_bet_3_and_7))\n",
    "x_clamp_below_by_3 = torch.clamp_min(x, min=3)\n",
    "print('x_clamp_below_by_3(x): {}'.format(x_clamp_below_by_3))\n",
    "x_clamp_above_by_7 = torch.clamp_max(x, max=7)\n",
    "print('x_clamp_above_by_7(x): {}'.format(x_clamp_above_by_7))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "tensor([[1, 1, 0],\n",
      "        [0, 1, 0]])\n",
      "y: \n",
      "tensor([[0, 1, 1],\n",
      "        [0, 0, 1]])\n",
      "*******************************************************************************\n",
      "x==y: \n",
      "tensor([[False,  True, False],\n",
      "        [ True, False, False]])\n",
      "x<y: \n",
      "tensor([[False, False,  True],\n",
      "        [False, False,  True]])\n",
      "x<=y: \n",
      "tensor([[False,  True,  True],\n",
      "        [ True, False,  True]])\n",
      "x>y: \n",
      "tensor([[ True, False, False],\n",
      "        [False,  True, False]])\n",
      "x>=y: \n",
      "tensor([[ True,  True, False],\n",
      "        [ True,  True, False]])\n"
     ]
    }
   ],
   "source": [
    "# Comparison operations. Broadcasting is supported\n",
    "x = torch.randint(low=0, high=2, size=(2, 3))\n",
    "y = torch.randint(low=0, high=2, size=(2, 3))\n",
    "print('x: \\n{}'.format(x))\n",
    "print('y: \\n{}'.format(y))\n",
    "print('*'*79)\n",
    "x_eq_y = torch.eq(input=x, other=y)\n",
    "print('x==y: \\n{}'.format(x_eq_y))\n",
    "x_less_than_y = torch.less(input=x, other=y)\n",
    "print('x<y: \\n{}'.format(x_less_than_y))\n",
    "x_less_equal_y = torch.less_equal(input=x, other=y)\n",
    "print('x<=y: \\n{}'.format(x_less_equal_y))\n",
    "x_greater_than_y = torch.greater(input=x, other=y)\n",
    "print('x>y: \\n{}'.format(x_greater_than_y))\n",
    "x_greater_equal_y = torch.greater_equal(input=x, other=y)\n",
    "print('x>=y: \\n{}'.format(x_greater_equal_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "tensor([[1, 1, 5],\n",
      "        [2, 5, 3]])\n",
      "sum(x): \n",
      "17\n",
      "mean(x): \n",
      "2.8333332538604736\n",
      "product(x): \n",
      "150\n",
      "min(x): \n",
      "1\n",
      "max(x): \n",
      "5\n",
      "*******************************************************************************\n",
      "x: \n",
      "tensor([[[3, 2, 5, 4],\n",
      "         [3, 3, 5, 5],\n",
      "         [3, 4, 1, 3]],\n",
      "\n",
      "        [[1, 1, 3, 3],\n",
      "         [1, 3, 4, 3],\n",
      "         [1, 1, 4, 5]]]),\n",
      "shape: torch.Size([2, 3, 4])\n",
      "sum(x): \n",
      "tensor([[[4, 3, 8, 7],\n",
      "         [4, 6, 9, 8],\n",
      "         [4, 5, 5, 8]]]),\n",
      "shape: torch.Size([1, 3, 4])\n",
      "*******************************************************************************\n",
      "product(x): \n",
      "tensor([[[27, 24, 25, 60]],\n",
      "\n",
      "        [[ 1,  3, 48, 45]]]),\n",
      "shape: torch.Size([2, 1, 4])\n",
      "mean(x): \n",
      "tensor([[[3.5000],\n",
      "         [4.0000],\n",
      "         [2.7500]],\n",
      "\n",
      "        [[2.0000],\n",
      "         [2.7500],\n",
      "         [2.7500]]]),\n",
      "shape: torch.Size([2, 3, 1])\n",
      "product(x): \n",
      "tensor([[[27, 24, 25, 60]],\n",
      "\n",
      "        [[ 1,  3, 48, 45]]]),\n",
      "shape: torch.Size([2, 1, 4])\n",
      "mean(x): \n",
      "tensor([[[3.5000],\n",
      "         [4.0000],\n",
      "         [2.7500]],\n",
      "\n",
      "        [[2.0000],\n",
      "         [2.7500],\n",
      "         [2.7500]]]),\n",
      "shape: torch.Size([2, 3, 1])\n",
      "results with appropriately negated dimensions match: True\n",
      "*******************************************************************************\n",
      "x: \n",
      "tensor([[[2, 9],\n",
      "         [1, 2],\n",
      "         [1, 5]],\n",
      "\n",
      "        [[7, 2],\n",
      "         [5, 6],\n",
      "         [3, 8]],\n",
      "\n",
      "        [[1, 1],\n",
      "         [1, 5],\n",
      "         [1, 9]],\n",
      "\n",
      "        [[9, 7],\n",
      "         [6, 9],\n",
      "         [9, 3]]]),\n",
      "shape: torch.Size([4, 3, 2])\n",
      "unique elements in x: \n",
      "tensor([1, 2, 3, 5, 6, 7, 8, 9])\n",
      "indices of unique elements in x: \n",
      "tensor([[[1, 7],\n",
      "         [0, 1],\n",
      "         [0, 3]],\n",
      "\n",
      "        [[5, 1],\n",
      "         [3, 4],\n",
      "         [2, 6]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [0, 3],\n",
      "         [0, 7]],\n",
      "\n",
      "        [[7, 5],\n",
      "         [4, 7],\n",
      "         [7, 2]]])\n",
      "counts of unique elements in x: \n",
      "tensor([6, 3, 2, 3, 2, 2, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "# Reduction operations.\n",
    "x = torch.randint(low=1, high=6, size=(2, 3))\n",
    "print('x: \\n{}'.format(x))\n",
    "x_sum = torch.sum(x)\n",
    "print('sum(x): \\n{}'.format(x_sum))\n",
    "x_mean = torch.mean(x.to(torch.float32))  # `torch.mean` only operates on float and not int/long.\n",
    "print('mean(x): \\n{}'.format(x_mean))\n",
    "x_product = torch.prod(x)\n",
    "print('product(x): \\n{}'.format(x_product))\n",
    "x_min = torch.min(x)\n",
    "print('min(x): \\n{}'.format(x_min))\n",
    "x_max = torch.max(x)\n",
    "print('max(x): \\n{}'.format(x_max))\n",
    "# Reductions along specific dimensions.\n",
    "# `keepdim` enables preserving the result shape and thus, is a good practice!\n",
    "print('*'*79)\n",
    "x = torch.randint(low=1, high=6, size=(2, 3, 4))\n",
    "print('x: \\n{},\\nshape: {}'.format(x, x.shape))\n",
    "x_sum_dim_0 = torch.sum(x, dim=0, keepdim=True)\n",
    "print('sum(x): \\n{},\\nshape: {}'.format(x_sum_dim_0, x_sum_dim_0.shape))\n",
    "print('*'*79)\n",
    "x_prod_dim_1 = torch.prod(x, dim=1, keepdim=True)\n",
    "print('product(x): \\n{},\\nshape: {}'.format(x_prod_dim_1, x_prod_dim_1.shape))\n",
    "x_mean_dim_2 = torch.mean(x.float(), dim=2, keepdim=True)  # `torch.mean` operates on floats!\n",
    "print('mean(x): \\n{},\\nshape: {}'.format(x_mean_dim_2, x_mean_dim_2.shape))\n",
    "# The next two results must match the previous two in order!\n",
    "x_prod_dim_minus2 = torch.prod(x, dim=-2, keepdim=True)  # `torch.mean` operates on floats!\n",
    "print('product(x): \\n{},\\nshape: {}'.format(x_prod_dim_minus2, x_prod_dim_minus2.shape))\n",
    "x_mean_dim_minus1 = torch.mean(x.float(), dim=-1, keepdim=True)\n",
    "print('mean(x): \\n{},\\nshape: {}'.format(x_mean_dim_minus1, x_mean_dim_minus1.shape))\n",
    "# The results with negative dimensions match the standard ones!\n",
    "print('results with appropriately negated dimensions match: {}'.format(\n",
    "    torch.all(torch.eq(x_prod_dim_1, x_prod_dim_minus2)) and\\\n",
    "    torch.all(torch.eq(x_mean_dim_2, x_mean_dim_minus1))\n",
    "))\n",
    "# Filter unique elements.\n",
    "print('*'*79)\n",
    "x = torch.randint(low=0, high=10, size=(4, 3, 2))\n",
    "print('x: \\n{},\\nshape: {}'.format(x, x.shape))\n",
    "x_unique, x_indices, x_counts = torch.unique(\n",
    "    input=x, sorted=True, return_inverse=True, return_counts=True, dim=None\n",
    ")\n",
    "print('unique elements in x: \\n{}'.format(x_unique))\n",
    "print('indices of unique elements in x: \\n{}'.format(x_indices))\n",
    "print('counts of unique elements in x: \\n{}'.format(x_counts))\n",
    "# The \"indices\" tell to which output index did the current input element was mapped."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: tensor([1, 4, 1])\n",
      "x2: tensor([4, 2, 2])\n",
      "<x1, x2>: 14\n",
      "<x1, x2>: 14\n",
      "x1 X x2: tensor([  6,   2, -14])\n",
      "i X j: tensor([0., 0., 1.]), j X i: tensor([ 0.,  0., -1.])\n",
      "*******************************************************************************\n",
      "m1: \n",
      "tensor([[ 0.3296, -0.8763, -1.6768],\n",
      "        [-0.7247,  0.9634,  0.1342]])\n",
      "m2: \n",
      "tensor([[ 0.5485,  2.1349],\n",
      "        [-0.8782, -2.0826],\n",
      "        [ 1.8317, -0.5535]])\n",
      "m1*m2 = \n",
      "tensor([[-2.1211,  3.4569],\n",
      "        [-0.9977, -3.6278]])\n",
      "m1*m2 = \n",
      "tensor([[-2.1211,  3.4569],\n",
      "        [-0.9977, -3.6278]])\n",
      "m1 o m2 = \n",
      "tensor([[ 0.1808,  0.7695, -3.0714],\n",
      "        [-1.5471, -2.0064, -0.0743]])\n",
      "m2: \n",
      "tensor([[ 0.5485,  2.1349],\n",
      "        [-0.8782, -2.0826],\n",
      "        [ 1.8317, -0.5535]])\n",
      "(m2)^T: \n",
      "tensor([[ 0.5485, -0.8782,  1.8317],\n",
      "        [ 2.1349, -2.0826, -0.5535]])\n",
      "*******************************************************************************\n",
      "x1: \n",
      "tensor([[[0, 4, 4],\n",
      "         [3, 2, 3]],\n",
      "\n",
      "        [[1, 1, 4],\n",
      "         [4, 3, 0]],\n",
      "\n",
      "        [[3, 0, 0],\n",
      "         [4, 1, 2]],\n",
      "\n",
      "        [[1, 1, 4],\n",
      "         [4, 4, 2]]])\n",
      "x2: \n",
      "tensor([[[2, 0],\n",
      "         [1, 2],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[1, 3],\n",
      "         [1, 0],\n",
      "         [2, 2]],\n",
      "\n",
      "        [[4, 2],\n",
      "         [1, 2],\n",
      "         [1, 1]],\n",
      "\n",
      "        [[4, 1],\n",
      "         [2, 4],\n",
      "         [0, 4]]])\n",
      "x1 * x2 = \n",
      "tensor([[[ 4,  8],\n",
      "         [ 8,  4]],\n",
      "\n",
      "        [[10, 11],\n",
      "         [ 7, 12]],\n",
      "\n",
      "        [[12,  6],\n",
      "         [19, 12]],\n",
      "\n",
      "        [[ 6, 21],\n",
      "         [24, 28]]])\n",
      "torch.matmul performs batchwise computation: True\n",
      "torch.matmul performs batchwise computation: True\n",
      "torch.matmul performs batchwise computation: True\n",
      "torch.matmul performs batchwise computation: True\n",
      "x1 @ x2 = \n",
      "tensor([[[ 4,  8],\n",
      "         [ 8,  4]],\n",
      "\n",
      "        [[10, 11],\n",
      "         [ 7, 12]],\n",
      "\n",
      "        [[12,  6],\n",
      "         [19, 12]],\n",
      "\n",
      "        [[ 6, 21],\n",
      "         [24, 28]]])\n",
      "torch.matmul performs batchwise computation: True\n",
      "torch.matmul performs batchwise computation: True\n",
      "torch.matmul performs batchwise computation: True\n",
      "torch.matmul performs batchwise computation: True\n"
     ]
    }
   ],
   "source": [
    "# Vector calculations.\n",
    "x1 = torch.tensor(data=np.random.randint(low=0, high=5, size=(3, )))\n",
    "x2 = torch.tensor(data=np.random.randint(low=0, high=5, size=(3, )))\n",
    "print('x1: {}\\nx2: {}'.format(x1, x2))\n",
    "print('<x1, x2>: {}'.format(torch.dot(input=x1, tensor=x2)))\n",
    "print('<x1, x2>: {}'.format(torch.vdot(input=x1, other=x2)))\n",
    "print('x1 X x2: {}'.format(torch.cross(input=x1, other=x2)))  # Behavior with `dim != 3` is weird!\n",
    "print('i X j: {}, j X i: {}'.format(\n",
    "    torch.cross(\n",
    "        input=torch.tensor(data=[1., 0., 0.]),\n",
    "        other=torch.tensor(data=[0., 1., 0.]),\n",
    "    ),\n",
    "    torch.cross(\n",
    "        input=torch.tensor(data=[0., 1., 0.]),\n",
    "        other=torch.tensor(data=[1., 0., 0.]),\n",
    "    )\n",
    "))  # Right-hand convention: i X j = k. Also, as expected, i X j = -j X i.\n",
    "# Matrix calculations.\n",
    "print('*'*79)\n",
    "m1 = torch.Tensor(size=(2, 3)).normal_()  # torch.Tensor(3, 4) also works. Behaves similarly to `torch.empty`.\n",
    "m2 = torch.Tensor(size=(3, 2)).normal_()\n",
    "print('m1: \\n{}\\nm2: \\n{}'.format(m1, m2))\n",
    "print('m1*m2 = \\n{}'.format(torch.matmul(input=m1, other=m2)))\n",
    "print('m1*m2 = \\n{}'.format(torch.mm(input=m1, mat2=m2)))\n",
    "print('m1 o m2 = \\n{}'.format(torch.mul(input=m1, other=m2.T)))  # `.T` transposes.\n",
    "# Changing dimensions.\n",
    "m2_transpose = m2.permute(1, 0)\n",
    "print('m2: \\n{}\\n(m2)^T: \\n{}'.format(m2, m2_transpose))\n",
    "# Matrix operations on batches of matrices (`torch.matmul` and `@`).\n",
    "print('*'*79)\n",
    "x1 = torch.randint(low=0, high=5, size=(4, 2, 3))\n",
    "x2 = torch.randint(low=0, high=5, size=(4, 3, 2))\n",
    "print('x1: \\n{}\\nx2: \\n{}'.format(x1, x2))\n",
    "print('x1 * x2 = \\n{}'.format(torch.matmul(input=x1, other=x2)))\n",
    "for idx in range(4):\n",
    "    individual_mat_prod = torch.mm(input=x1[idx], mat2=x2[idx])\n",
    "    calculated_mat_prod = torch.matmul(input=x1, other=x2)[idx]\n",
    "    print('torch.matmul performs batchwise computation: {}'.format(\n",
    "        torch.all(\n",
    "            torch.eq(input=individual_mat_prod, other=calculated_mat_prod)\n",
    "        )\n",
    "    ))\n",
    "print('x1 @ x2 = \\n{}'.format(x1@x2))\n",
    "for idx in range(4):\n",
    "    individual_mat_prod = torch.mm(input=x1[idx], mat2=x2[idx])\n",
    "    calculated_mat_prod = (x1@x2)[idx]\n",
    "    print('torch.matmul performs batchwise computation: {}'.format(\n",
    "        torch.all(\n",
    "            torch.eq(input=individual_mat_prod, other=calculated_mat_prod)\n",
    "        )\n",
    "    ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "determinant(\n",
      " tensor([[3., 2.],\n",
      "        [4., 3.]]) \n",
      ") =  tensor(1.)\n",
      "*******************************************************************************\n",
      "eigenpair(\n",
      " tensor([[3., 2.],\n",
      "        [4., 3.]]) \n",
      ") =  torch.return_types.eig(\n",
      "eigenvalues=tensor([[5.8284, 0.0000],\n",
      "        [0.1716, 0.0000]]),\n",
      "eigenvectors=tensor([[ 0.5774, -0.5774],\n",
      "        [ 0.8165,  0.8165]]))\n",
      "eigenvalues: \n",
      "tensor([[5.8284, 0.0000],\n",
      "        [0.1716, 0.0000]])\n",
      "shape: \n",
      "torch.Size([2, 2])\n",
      "eigenvectors: \n",
      "tensor([[ 0.5774, -0.5774],\n",
      "        [ 0.8165,  0.8165]])\n",
      "shape: \n",
      "torch.Size([2, 2])\n",
      "error(A*x_1, lambda_1*x_1): \n",
      "2.384185791015625e-07\n",
      "error(A*x_2, lambda_2*x_2): \n",
      "1.4901161193847656e-07\n",
      "*******************************************************************************\n",
      "svd(\n",
      " tensor([[0.7189, 0.0897],\n",
      "        [0.3745, 0.2345],\n",
      "        [0.8760, 0.5965]]) \n",
      ") =  torch.return_types.linalg_svd(\n",
      "U=tensor([[-0.5141,  0.8564],\n",
      "        [-0.3313, -0.1469],\n",
      "        [-0.7911, -0.4950]]),\n",
      "S=tensor([1.3279, 0.2830]),\n",
      "V=tensor([[-0.8937, -0.4487],\n",
      "        [ 0.4487, -0.8937]]))\n",
      "x.shape: torch.Size([3, 2]) U.shape: torch.Size([3, 2]) S.shape: torch.Size([2]) V.shape: torch.Size([2, 2])\n",
      "U*S*V^T =  tensor([[0.7189, 0.0897],\n",
      "        [0.3745, 0.2345],\n",
      "        [0.8760, 0.5965]])\n",
      "U*S*V^T =  tensor([[0.7189, 0.0897],\n",
      "        [0.3745, 0.2345],\n",
      "        [0.8760, 0.5965]])\n",
      "error(x, U*S*V^T) =  tensor(7.3000e-08)\n",
      "*******************************************************************************\n",
      "svd(\n",
      " tensor([[[0.7319, 0.1614],\n",
      "         [0.9214, 0.5446],\n",
      "         [0.2227, 0.4673]],\n",
      "\n",
      "        [[0.1460, 0.4769],\n",
      "         [0.7792, 0.2752],\n",
      "         [0.9226, 0.6527]],\n",
      "\n",
      "        [[0.4125, 0.6562],\n",
      "         [0.4079, 0.3838],\n",
      "         [0.1720, 0.7913]],\n",
      "\n",
      "        [[0.8001, 0.6712],\n",
      "         [0.7957, 0.9995],\n",
      "         [0.9708, 0.0175]]]) \n",
      ") =  torch.return_types.linalg_svd(\n",
      "U=tensor([[[-0.5294,  0.5829],\n",
      "         [-0.7892, -0.0717],\n",
      "         [-0.3114, -0.8094]],\n",
      "\n",
      "        [[-0.2679,  0.8411],\n",
      "         [-0.5576, -0.5331],\n",
      "         [-0.7857,  0.0916]],\n",
      "\n",
      "        [[-0.6327, -0.2567],\n",
      "         [-0.4314, -0.6667],\n",
      "         [-0.6431,  0.6997]],\n",
      "\n",
      "        [[-0.5799, -0.0810],\n",
      "         [-0.6879, -0.4844],\n",
      "         [-0.4365,  0.8711]]]),\n",
      "S=tensor([[1.3558, 0.3701],\n",
      "        [1.4377, 0.3769],\n",
      "        [1.2195, 0.2882],\n",
      "        [1.7988, 0.6559]]),\n",
      "V=tensor([[[-0.8732, -0.4873],\n",
      "         [ 0.4873, -0.8732]],\n",
      "\n",
      "        [[-0.8336, -0.5523],\n",
      "         [-0.5523,  0.8336]],\n",
      "\n",
      "        [[-0.4490, -0.8935],\n",
      "         [-0.8935,  0.4490]],\n",
      "\n",
      "        [[-0.7978, -0.6029],\n",
      "         [ 0.6029, -0.7978]]]))\n",
      "x.shape: torch.Size([4, 3, 2]) U.shape: torch.Size([4, 3, 2]) S.shape: torch.Size([4, 2]) V.shape: torch.Size([4, 2, 2])\n",
      "U*S*V^T =  tensor([[[0.7319, 0.1614],\n",
      "         [0.9214, 0.5446],\n",
      "         [0.2227, 0.4673]],\n",
      "\n",
      "        [[0.1460, 0.4769],\n",
      "         [0.7792, 0.2752],\n",
      "         [0.9226, 0.6527]],\n",
      "\n",
      "        [[0.4125, 0.6562],\n",
      "         [0.4079, 0.3838],\n",
      "         [0.1720, 0.7913]],\n",
      "\n",
      "        [[0.8001, 0.6712],\n",
      "         [0.7957, 0.9995],\n",
      "         [0.9708, 0.0175]]])\n",
      "error(x, U*S*V^T) =  tensor(4.1161e-07)\n"
     ]
    }
   ],
   "source": [
    "# Linear algebra.\n",
    "x = torch.tensor(data=[[3, 2], [4, 3]]).float()\n",
    "# Determinant.\n",
    "print('determinant(\\n', x, '\\n) = ', torch.det(x))\n",
    "# Eigenpairs.\n",
    "print('*'*79)\n",
    "print('eigenpair(\\n', x, '\\n) = ', torch.eig(input=x, eigenvectors=True))\n",
    "print('eigenvalues: \\n{}\\nshape: \\n{}'.format(\n",
    "    torch.eig(input=x, eigenvectors=True)[0],\n",
    "    torch.eig(input=x, eigenvectors=True)[0].shape\n",
    "))\n",
    "print('eigenvectors: \\n{}\\nshape: \\n{}'.format(\n",
    "    torch.eig(input=x, eigenvectors=True)[1],\n",
    "    torch.eig(input=x, eigenvectors=True)[1].shape\n",
    "))\n",
    "lambdas, xs = torch.eig(input=x, eigenvectors=True)\n",
    "lambda_1, lambda_2 = lambdas[0, 0], lambdas[1, 0]\n",
    "x_1, x_2 = xs[:, 0].view(-1, 1), xs[:, 1].view(-1, 1)\n",
    "print('error(A*x_1, lambda_1*x_1): \\n{}'.format(\n",
    "    torch.dist(torch.mm(input=x, mat2=x_1), lambda_1*x_1)\n",
    "))\n",
    "print('error(A*x_2, lambda_2*x_2): \\n{}'.format(\n",
    "    torch.dist(torch.mm(input=x, mat2=x_2), lambda_2*x_2)\n",
    "))\n",
    "# Singular value decomposition of a single matrix.\n",
    "print('*'*79)\n",
    "x = torch.rand(3, 2)  # SVD of a single matrix\n",
    "print('svd(\\n', x, '\\n) = ', torch.linalg.svd(x, full_matrices=False))\n",
    "u, s, v_transpose = torch.linalg.svd(x, full_matrices=False)\n",
    "print('x.shape:', x.shape, 'U.shape:', u.shape, 'S.shape:', s.shape, 'V.shape:', v_transpose.shape)\n",
    "print('U*S*V^T = ', u @ torch.diag_embed(s) @ v_transpose)\n",
    "print('U*S*V^T = ', torch.mm(torch.mm(u, torch.diag(s)), v_transpose))\n",
    "print('error(x, U*S*V^T) = ', torch.dist(torch.mm(torch.mm(u, torch.diag(s)), v_transpose), x))\n",
    "# Singular value decomposition of a batch of matrices.\n",
    "print('*'*79)\n",
    "x = torch.rand(4, 3, 2)  # SVD of a batch of matrices\n",
    "print('svd(\\n', x, '\\n) = ', torch.linalg.svd(x, full_matrices=False))\n",
    "u, s, v_transpose = torch.linalg.svd(x, full_matrices=False)\n",
    "print('x.shape:', x.shape, 'U.shape:', u.shape, 'S.shape:', s.shape, 'V.shape:', v_transpose.shape)\n",
    "print('U*S*V^T = ', u @ torch.diag_embed(s) @ v_transpose)\n",
    "\"\"\"\n",
    "@ performs ([m, n], [n, p] -> [m, p]) matrix multiplications on [<dims>, m, n]\n",
    "and [<dims>, n, p] tensors to produces [<dims>, m, p] output.\n",
    "diag_embed changes a [<dims>, n] dimensional array into [<dims>, n, n] tensor\n",
    "with nxn diagonal matrices for each of the rows.\n",
    "\"\"\"\n",
    "print('error(x, U*S*V^T) = ', torch.dist(u @ torch.diag_embed(s) @ v_transpose, x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "x1 + x2: \n",
      "tensor([2., 4., 6.])\n",
      "x1: \n",
      "tensor([1., 2., 3.])\n",
      "x2: \n",
      "tensor([4., 5., 6.])\n",
      "*******************************************************************************\n",
      "x1 + x2: \n",
      "tensor([5., 7., 9.])\n",
      "x1: \n",
      "tensor([5., 7., 9.])\n",
      "x2: \n",
      "tensor([4., 5., 6.])\n",
      "*******************************************************************************\n",
      "x1 - x2: \n",
      "tensor([-3., -3., -3.])\n",
      "x1: \n",
      "tensor([-3., -3., -3.])\n",
      "x2: \n",
      "tensor([4., 5., 6.])\n",
      "*******************************************************************************\n",
      "x1 o x2: \n",
      "tensor([ 4., 10., 18.])\n",
      "x1: \n",
      "tensor([ 4., 10., 18.])\n",
      "x2: \n",
      "tensor([4., 5., 6.])\n",
      "*******************************************************************************\n",
      "x1 / x2: \n",
      "tensor([0.2500, 0.4000, 0.5000])\n",
      "x1: \n",
      "tensor([0.2500, 0.4000, 0.5000])\n",
      "x2: \n",
      "tensor([4., 5., 6.])\n",
      "*******************************************************************************\n",
      "sin(x1): \n",
      "tensor([0.8415, 0.9093, 0.1411])\n",
      "arccos(x2/6): \n",
      "tensor([0.8411, 0.5857, 0.0000])\n",
      "x1: \n",
      "tensor([0.8415, 0.9093, 0.1411])\n",
      "x2: \n",
      "tensor([0.8411, 0.5857, 0.0000])\n",
      "*******************************************************************************\n",
      "x_out_1: \n",
      "tensor([[1.5414e-44, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00]])\n",
      "id: \n",
      "5309841984\n",
      "x_out_2: \n",
      "tensor([0., 2., 0.])\n",
      "id: \n",
      "5309984000\n",
      "x3: \n",
      "tensor([[2., 4.],\n",
      "        [6., 9.]])\n",
      "x_out_1: \n",
      "tensor([[2., 4.],\n",
      "        [6., 9.]])\n",
      "x3 is the same object as x_out_1: True\n",
      "id(x3): 5309841984, id(x_out_1): 5309841984\n",
      "x3 and x_out_1 ids are the same: True\n",
      "x4: \n",
      "tensor([[2.0000, 3.5000]])\n",
      "x_out_2: \n",
      "tensor([[2.0000, 3.5000]])\n",
      "x4 is the same object as x_out_2: True\n",
      "id(x4): 5309984000, id(x_out_2): 5309984000\n",
      "x4 and x_out_2 ids are the same: True\n"
     ]
    }
   ],
   "source": [
    "# In-place tensor operations.\n",
    "x1 = torch.tensor(data=[1.0, 2.0, 3.0])\n",
    "x2 = torch.tensor(data=[4.0, 5.0, 6.0])\n",
    "print('*'*79)\n",
    "print('x1 + x2: \\n{}'.format(torch.add(input=x1, other=x1)))\n",
    "print('x1: \\n{}\\nx2: \\n{}'.format(x1, x2))\n",
    "#\n",
    "x1 = torch.tensor(data=[1.0, 2.0, 3.0])\n",
    "x2 = torch.tensor(data=[4.0, 5.0, 6.0])\n",
    "print('*'*79)\n",
    "print('x1 + x2: \\n{}'.format(x1.add_(x2)))\n",
    "print('x1: \\n{}\\nx2: \\n{}'.format(x1, x2))\n",
    "#\n",
    "x1 = torch.tensor(data=[1.0, 2.0, 3.0])\n",
    "x2 = torch.tensor(data=[4.0, 5.0, 6.0])\n",
    "print('*'*79)\n",
    "print('x1 - x2: \\n{}'.format(x1.sub_(x2)))\n",
    "print('x1: \\n{}\\nx2: \\n{}'.format(x1, x2))\n",
    "#\n",
    "x1 = torch.tensor(data=[1.0, 2.0, 3.0])\n",
    "x2 = torch.tensor(data=[4.0, 5.0, 6.0])\n",
    "print('*'*79)\n",
    "print('x1 o x2: \\n{}'.format(x1.mul_(x2)))\n",
    "print('x1: \\n{}\\nx2: \\n{}'.format(x1, x2))\n",
    "#\n",
    "x1 = torch.tensor(data=[1.0, 2.0, 3.0])\n",
    "x2 = torch.tensor(data=[4.0, 5.0, 6.0])\n",
    "print('*'*79)\n",
    "print('x1 / x2: \\n{}'.format(x1.div_(x2)))\n",
    "print('x1: \\n{}\\nx2: \\n{}'.format(x1, x2))\n",
    "#\n",
    "x1 = torch.tensor(data=[1.0, 2.0, 3.0])\n",
    "x2 = torch.tensor(data=[4.0, 5.0, 6.0])\n",
    "print('*'*79)\n",
    "print('sin(x1): \\n{}'.format(x1.sin_()))\n",
    "print('arccos(x2/6): \\n{}'.format(x2.div_(6).arccos_()))\n",
    "print('x1: \\n{}\\nx2: \\n{}'.format(x1, x2))\n",
    "# Set operation outputs to existing tensor memory locations.\n",
    "x1 = torch.tensor([[1.0, 2.0], [3.0, 4]])\n",
    "x2 = torch.tensor([[1.0, 2.0], [3.0, 5.0]])\n",
    "print('*'*79)\n",
    "x_out_1 = torch.Tensor(2, 2)\n",
    "x_out_2 = torch.Tensor(3, )\n",
    "out_id_1 = id(x_out_1)\n",
    "out_id_2 = id(x_out_2)\n",
    "print('x_out_1: \\n{}\\nid: \\n{}'.format(x_out_1, out_id_1))  # Should hold garbage!\n",
    "print('x_out_2: \\n{}\\nid: \\n{}'.format(x_out_2, out_id_2))  # Should hold garbage!\n",
    "x3 = torch.add(input=x1, other=x2, out=x_out_1)  # x3 and x_out_1 are now the SAME OBJECTS (just different identifiers)!\n",
    "print('x3: \\n{}\\nx_out_1: \\n{}'.format(x3, x_out_1))\n",
    "print('x3 is the same object as x_out_1: {}'.format(x3 is x_out_1))\n",
    "print('id(x3): {}, id(x_out_1): {}'.format(id(x3), out_id_1))\n",
    "print('x3 and x_out_1 ids are the same: {}'.format(id(x3) == out_id_1))\n",
    "# If dimensions of the original do not match, they are updated!\n",
    "x4 = torch.mean(input=x2, dim=0, keepdim=True, out=x_out_2)  # output has two dimensions but `x_out_2` had only 1!\n",
    "print('x4: \\n{}\\nx_out_2: \\n{}'.format(x4, x_out_2))\n",
    "print('x4 is the same object as x_out_2: {}'.format(x4 is x_out_2))\n",
    "print('id(x4): {}, id(x_out_2): {}'.format(id(x4), out_id_2))\n",
    "print('x4 and x_out_2 ids are the same: {}'.format(id(x4) == out_id_2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "tensor([[[[1, 2, 1, 2],\n",
      "          [0, 0, 4, 3],\n",
      "          [0, 3, 2, 3],\n",
      "          [0, 3, 0, 4],\n",
      "          [3, 3, 3, 0]],\n",
      "\n",
      "         [[1, 0, 0, 0],\n",
      "          [4, 0, 0, 0],\n",
      "          [0, 3, 3, 2],\n",
      "          [2, 1, 3, 4],\n",
      "          [2, 1, 1, 4]]],\n",
      "\n",
      "\n",
      "        [[[2, 3, 1, 2],\n",
      "          [3, 1, 3, 3],\n",
      "          [2, 0, 1, 2],\n",
      "          [2, 4, 0, 0],\n",
      "          [0, 3, 3, 2]],\n",
      "\n",
      "         [[0, 4, 3, 0],\n",
      "          [4, 3, 4, 2],\n",
      "          [0, 4, 2, 2],\n",
      "          [1, 1, 4, 2],\n",
      "          [1, 2, 3, 3]]],\n",
      "\n",
      "\n",
      "        [[[4, 0, 4, 2],\n",
      "          [3, 1, 3, 3],\n",
      "          [4, 3, 3, 2],\n",
      "          [3, 1, 1, 4],\n",
      "          [3, 1, 1, 2]],\n",
      "\n",
      "         [[2, 2, 3, 4],\n",
      "          [4, 2, 1, 1],\n",
      "          [2, 2, 2, 3],\n",
      "          [2, 1, 4, 1],\n",
      "          [4, 3, 2, 1]]]])\n",
      "x[0]: \n",
      "tensor([[[1, 2, 1, 2],\n",
      "         [0, 0, 4, 3],\n",
      "         [0, 3, 2, 3],\n",
      "         [0, 3, 0, 4],\n",
      "         [3, 3, 3, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0],\n",
      "         [4, 0, 0, 0],\n",
      "         [0, 3, 3, 2],\n",
      "         [2, 1, 3, 4],\n",
      "         [2, 1, 1, 4]]])\n",
      "x[0, 1]: \n",
      "tensor([[1, 0, 0, 0],\n",
      "        [4, 0, 0, 0],\n",
      "        [0, 3, 3, 2],\n",
      "        [2, 1, 3, 4],\n",
      "        [2, 1, 1, 4]])\n",
      "x[0][1]: \n",
      "tensor([[1, 0, 0, 0],\n",
      "        [4, 0, 0, 0],\n",
      "        [0, 3, 3, 2],\n",
      "        [2, 1, 3, 4],\n",
      "        [2, 1, 1, 4]])\n",
      "x[0, 1] == x[0][1]: \n",
      "True\n",
      "x[2][1][2] == x[2,1,2]: \n",
      "True\n",
      "x[2][1][2] == x[2][1,2]: \n",
      "True\n",
      "x[2][1][2] == x[2,1][2]: \n",
      "True\n",
      "*******************************************************************************\n",
      "x: \n",
      "tensor([[2.3399, 0.3624],\n",
      "        [0.6607, 0.8704]])\n",
      "y: \n",
      "tensor([[2.3399, 0.3624],\n",
      "        [0.6607, 0.8704]])\n",
      "x is y: True\n",
      "x[0][0]: 2.3399105072021484\n",
      "x[0][0]: 1000.0\n",
      "*******************************************************************************\n",
      "x: \n",
      "tensor([[ 0.6971, -0.5599],\n",
      "        [ 0.7399, -0.4355]])\n",
      "z: \n",
      "tensor([[ 0.6971, -0.5599],\n",
      "        [ 0.7399, -0.4355]])\n",
      "x is z: False\n",
      "x[0][0]: 0.6970638036727905\n",
      "x[0][0]: 0.6970638036727905\n",
      "*******************************************************************************\n",
      "x: \n",
      "tensor([[-1.2849,  0.3738],\n",
      "        [ 0.8859, -1.7654]], requires_grad=True)\n",
      "u: \n",
      "tensor([[-1.2849,  0.3738],\n",
      "        [ 0.8859, -1.7654]], grad_fn=<CloneBackward>)\n",
      "v: \n",
      "tensor([[-1.2849,  0.3738],\n",
      "        [ 0.8859, -1.7654]])\n"
     ]
    }
   ],
   "source": [
    "# Slicing.\n",
    "x = torch.randint(low=0, high=5, size=(3, 2, 5, 4))  # `x` has 3 tensors of size (2, 4), each of which has 2 of size (4, ).\n",
    "print('x: \\n{}'.format(x))\n",
    "print('x[0]: \\n{}'.format(x[0]))\n",
    "print('x[0, 1]: \\n{}'.format(x[0, 1]))\n",
    "print('x[0][1]: \\n{}'.format(x[0][1]))\n",
    "print('x[0, 1] == x[0][1]: \\n{}'.format(\n",
    "    torch.all(torch.eq(input=x[0][1], other=x[0, 1]))\n",
    "))\n",
    "idx1, idx2, idx3 = \\\n",
    "    np.random.randint(low=0, high=3),\\\n",
    "    np.random.randint(low=0, high=2),\\\n",
    "    np.random.randint(low=0, high=5)\n",
    "print('x[{}][{}][{}] == x[{},{},{}]: \\n{}'.format(\n",
    "    idx1, idx2, idx3, idx1, idx2, idx3,\n",
    "    torch.all(torch.eq(input=x[idx1][idx2][idx3], other=x[idx1, idx2, idx3]))\n",
    "))\n",
    "print('x[{}][{}][{}] == x[{}][{},{}]: \\n{}'.format(\n",
    "    idx1, idx2, idx3, idx1, idx2, idx3,\n",
    "    torch.all(torch.eq(input=x[idx1][idx2][idx3], other=x[idx1][idx2, idx3]))\n",
    "))\n",
    "print('x[{}][{}][{}] == x[{},{}][{}]: \\n{}'.format(\n",
    "    idx1, idx2, idx3, idx1, idx2, idx3,\n",
    "    torch.all(torch.eq(input=x[idx1][idx2][idx3], other=x[idx1, idx2][idx3]))\n",
    "))\n",
    "# Assigning tensors.\n",
    "print('*'*79)\n",
    "x = torch.Tensor(2, 2).normal_()\n",
    "y = x\n",
    "print('x: \\n{}'.format(x))\n",
    "print('y: \\n{}'.format(y))\n",
    "print('x is y: {}'.format(x is y))  # True: assignment creates a label for the tensor.\n",
    "print('x[0][0]: {}'.format(x[0][0]))\n",
    "y[0][0] = 1000.0\n",
    "print('x[0][0]: {}'.format(x[0][0]))  # Gets updated as x is y.\n",
    "# Cloning tensors.\n",
    "print('*'*79)\n",
    "x = torch.Tensor(2, 2).normal_()\n",
    "z = x.clone()  # If `x` had autograd enabled, then so will be the case with `z`.\n",
    "print('x: \\n{}'.format(x))\n",
    "print('z: \\n{}'.format(z))\n",
    "print('x is z: {}'.format(x is z))  # False. Clone create a copy of the tensor.\n",
    "print('x[0][0]: {}'.format(x[0][0]))\n",
    "z[0][0] = 1000.0\n",
    "print('x[0][0]: {}'.format(x[0][0]))  # DOESN'T GET updated as x is not z.\n",
    "# Cloning tensors without requiring gradient.\n",
    "print('*'*79)\n",
    "x = torch.Tensor(2, 2).normal_().requires_grad_()\n",
    "u = x.clone()  # Tracks the history of `x` in order to backprop gradients.\n",
    "v = x.detach().clone()  # DOESN'T TRACK the history of `x`\n",
    "print('x: \\n{}'.format(x))\n",
    "print('u: \\n{}'.format(u))\n",
    "print('v: \\n{}'.format(v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is GPU available: \n",
      "False\n",
      "x: \n",
      "tensor([[2, 3],\n",
      "        [4, 2]])\n",
      "x: \n",
      "tensor([[2.6101e+20, 1.0415e-11],\n",
      "        [1.0621e-05, 1.3297e+22]])\n",
      "Exception: legacy constructor expects device type: cpubut device type: cuda was passed\n",
      "number of GPU devices: 0\n",
      "x: \n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "is x on GPU: False\n"
     ]
    }
   ],
   "source": [
    "# GPU-compatibility.\n",
    "print('is GPU available: \\n{}'.format(torch.cuda.is_available()))\n",
    "# Setting tensors to GPU.\n",
    "x = torch.tensor(data=([2, 3], (4, 2)))\n",
    "x = x.cuda() if torch.cuda.is_available() else x\n",
    "print('x: \\n{}'.format(x))\n",
    "# Alternate method.\n",
    "if torch.cuda.is_available():\n",
    "    x = torch.Tensor(2, 2, device='cuda')\n",
    "else:\n",
    "    x = torch.Tensor(2, 2)\n",
    "print('x: \\n{}'.format(x))\n",
    "try:\n",
    "    print('trying to set x on gpu: \\n{}'.format(torch.Tensor(2, 3, device='cuda').normal_()))\n",
    "except Exception as e:\n",
    "    print('Exception: {}'.format(e))\n",
    "# Devices in pytorch.\n",
    "device = torch.device('cpu')  # `torch.device('cuda')` for GPUs.\n",
    "print('number of GPU devices: {}'.format(torch.cuda.device_count()))\n",
    "# If more than one GPUs, say `n`, mention `torch.device('cuda:<i>')` for `0 <= i < n`.\n",
    "# Moving tensor to a specific device.\n",
    "my_device = torch.device('cpu')\n",
    "x = torch.tensor(data=((1, 2), (3, 4))).float()\n",
    "x = x.to(my_device)\n",
    "print('x: \\n{}\\nis x on GPU: {}'.format(x, x.is_cuda))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([3, 2, 4, 5])\n",
      "x.unsqueeze(dim=1).shape: torch.Size([3, 1, 2, 4, 5])\n",
      "y.unsqueeze(dim=1).shape: torch.Size([3, 1, 1, 2, 4, 5])\n",
      "y.unsqueeze(dim=2).shape: torch.Size([3, 1, 1, 2, 4, 5])\n",
      "x_squeezed.shape: torch.Size([3, 2, 4, 5])\n",
      "x_squeezed_dim_1.shape: torch.Size([3, 1, 2, 4, 5])\n",
      "*******************************************************************************\n",
      "x.shape: torch.Size([64, 3, 28, 28])\n",
      "x_channel_first.shape: torch.Size([3, 64, 28, 28])\n",
      "x_channel_first[0,5] == x[5,0]: True\n",
      "x_height_first.shape: torch.Size([28, 64, 3, 28])\n",
      "x[38,1,26] == x_height_first[26,38,1]: True\n",
      "*******************************************************************************\n",
      "x_2d_batched.shape: torch.Size([64, 3, 2, 2])\n",
      "x_flattened_batched.shape: torch.Size([64, 12])\n",
      "3*2*2 == 12: True\n",
      "*******************************************************************************\n",
      "x: \n",
      "tensor([[[8, 7, 7, 1],\n",
      "         [7, 6, 8, 7]],\n",
      "\n",
      "        [[6, 2, 7, 8],\n",
      "         [4, 8, 9, 5]],\n",
      "\n",
      "        [[9, 5, 0, 9],\n",
      "         [2, 3, 6, 7]]])\n",
      "y: \n",
      "tensor([8, 7, 7, 1, 7, 6, 8, 7, 6, 2, 7, 8, 4, 8, 9, 5, 9, 5, 0, 9, 2, 3, 6, 7])\n",
      "x is y: False\n",
      "x: \n",
      "tensor([[[8, 7, 7, 1],\n",
      "         [7, 6, 8, 7]],\n",
      "\n",
      "        [[6, 2, 7, 8],\n",
      "         [4, 8, 9, 5]],\n",
      "\n",
      "        [[9, 5, 0, 9],\n",
      "         [2, 3, 6, 7]]])\n",
      "z1: \n",
      "tensor([8, 7, 7, 1, 7, 6, 8, 7, 6, 2, 7, 8, 4, 8, 9, 5, 9, 5, 0, 9, 2, 3, 6, 7])\n",
      "z2: \n",
      "tensor([8, 7, 7, 1, 7, 6, 8, 7, 6, 2, 7, 8, 4, 8, 9, 5, 9, 5, 0, 9, 2, 3, 6, 7])\n",
      "x is z1: False\n",
      "z1 == z2: True\n",
      "*******************************************************************************\n",
      "x.shape: torch.Size([3, 2, 4, 5])\n",
      "x.shape: torch.Size([3, 2, 4, 5, 1])\n",
      "x.shape: torch.Size([3, 2, 1, 4, 5, 1])\n",
      "x.shape: torch.Size([3, 2, 4, 5])\n",
      "x.shape: torch.Size([3, 2, 4, 5, 1])\n",
      "x.shape: torch.Size([3, 2, 1, 4, 5, 1])\n",
      "x.shape: torch.Size([3, 2, 1, 4, 5])\n",
      "x.shape: torch.Size([3, 2, 4, 5])\n",
      "*******************************************************************************\n",
      "x: \n",
      "tensor([[3, 0, 8, 9],\n",
      "        [1, 7, 1, 7],\n",
      "        [0, 1, 6, 6]])\n",
      "x resized in place: \n",
      "tensor([[3, 0, 8],\n",
      "        [9, 1, 7]])\n",
      "y: \n",
      "tensor([[3, 3, 1, 2],\n",
      "        [8, 1, 4, 8],\n",
      "        [8, 9, 9, 1]])\n",
      "y resized in place: \n",
      "tensor([[3, 3, 1, 2, 8],\n",
      "        [1, 4, 8, 8, 9],\n",
      "        [9, 1, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Adding a dimension to a tensor at a particular location.\n",
    "x = torch.Tensor(3, 2, 4, 5).normal_()\n",
    "print('x.shape: {}'.format(x.shape))\n",
    "y = x.unsqueeze(dim=1)  # w.r.t. original tensor, add a dimension at index 1. SHAPE: [3, 1, 2, 4, 5].\n",
    "print('x.unsqueeze(dim=1).shape: {}'.format(y.shape))\n",
    "z1 = y.unsqueeze(dim=1)\n",
    "print('y.unsqueeze(dim=1).shape: {}'.format(z1.shape))\n",
    "z2 = y.unsqueeze(dim=2)\n",
    "print('y.unsqueeze(dim=2).shape: {}'.format(z2.shape))\n",
    "x_squeezed = z1.unsqueeze(dim=-1).squeeze()  # Removes ALL dimensions with size 1.\n",
    "print('x_squeezed.shape: {}'.format(x_squeezed.shape))\n",
    "x_squeezed_dim_1 = z2.squeeze(dim=2)\n",
    "print('x_squeezed_dim_1.shape: {}'.format(x_squeezed_dim_1.shape))  # SHAPE: [3, 1, 2, 4, 5].\n",
    "# `.squeeze(<...>)` works only when dimension is 1 along some index.\n",
    "# Re-orienting a tensor by changing the order of axes.\n",
    "print('*'*79)\n",
    "x = torch.Tensor(64, 3, 28, 28).normal_()\n",
    "print('x.shape: {}'.format(x.shape))\n",
    "x_channel_first = x.permute(1, 0, 2, 3)\n",
    "print('x_channel_first.shape: {}'.format(x_channel_first.shape))\n",
    "idx1 = np.random.randint(low=0, high=64)\n",
    "idx2 = np.random.randint(low=0, high=3)\n",
    "print('x_channel_first[{},{}] == x[{},{}]: {}'.format(\n",
    "    idx2, idx1, idx1, idx2,\n",
    "    torch.all(torch.eq(input=x[idx1, idx2], other=x_channel_first[idx2, idx1]))\n",
    "))\n",
    "x_height_first = x.permute(2, 0, 1, 3)\n",
    "print('x_height_first.shape: {}'.format(x_height_first.shape))\n",
    "idx1 = np.random.randint(low=0, high=64)\n",
    "idx2 = np.random.randint(low=0, high=3)\n",
    "idx3 = np.random.randint(low=0, high=28)\n",
    "print('x[{},{},{}] == x_height_first[{},{},{}]: {}'.format(\n",
    "    idx1, idx2, idx3, idx3, idx1, idx2,\n",
    "    torch.all(torch.eq(input=x[idx1, idx2, idx3], other=x_height_first[idx3, idx1, idx2]))\n",
    "))\n",
    "# Flatten out tensors.\n",
    "print('*'*79)\n",
    "x_2d_batched = torch.Tensor(64, 3, np.random.randint(0, 10), np.random.randint(0, 10)).normal_()\n",
    "print('x_2d_batched.shape: {}'.format(x_2d_batched.shape))\n",
    "B = x_2d_batched.shape[0]\n",
    "x_flattened_batched = x_2d_batched.view(B, -1)  # Whenever UNAMBIGUOUS, the missing dimension given by `-1` is evaluated.\n",
    "print('x_flattened_batched.shape: {}'.format(x_flattened_batched.shape))\n",
    "print('{} == {}: {}'.format(\n",
    "    '*'.join([str(dim) for dim in x_2d_batched.shape[1: ]]),\n",
    "    np.prod(np.array([dim for dim in x_2d_batched.shape[1: ]])),\n",
    "    np.prod(np.array([dim for dim in x_2d_batched.shape[1: ]]))==x_flattened_batched.shape[-1]\n",
    "))\n",
    "# Properties of viewing. `.view(<...>)` returns A NEW TENSOR with same data and given shape.\n",
    "print('*'*79)\n",
    "x = torch.randint(low=0, high=10, size=(3, 2, 4))\n",
    "y = x.view(-1)\n",
    "print('x: \\n{}'.format(x))\n",
    "print('y: \\n{}'.format(y))\n",
    "print('x is y: {}'.format(x is y))\n",
    "z1 = x.reshape(-1)\n",
    "z2 = x.view(-1)\n",
    "print('x: \\n{}'.format(x))\n",
    "print('z1: \\n{}'.format(z1))\n",
    "print('z2: \\n{}'.format(z2))\n",
    "print('x is z1: {}'.format(x is z1))\n",
    "print('z1 == z2: {}'.format(\n",
    "    torch.all(torch.eq(input=z1, other=z2))\n",
    "))\n",
    "# In place squeeze and unsqueeze.\n",
    "print('*'*79)\n",
    "x = torch.Tensor(3, 2, 4, 5).normal_()\n",
    "print('x.shape: {}'.format(x.shape))\n",
    "x.unsqueeze_(dim=-1)\n",
    "print('x.shape: {}'.format(x.shape))  # Shape is changed in place.\n",
    "x.unsqueeze_(dim=2)\n",
    "print('x.shape: {}'.format(x.shape))  # Shape is changed in place.\n",
    "x.squeeze_()\n",
    "print('x.shape: {}'.format(x.shape))  # Shape is changed in place.\n",
    "x.unsqueeze_(dim=-1)\n",
    "print('x.shape: {}'.format(x.shape))  # Shape is changed in place.\n",
    "x.unsqueeze_(dim=2)\n",
    "print('x.shape: {}'.format(x.shape))  # Shape is changed in place.\n",
    "x.squeeze_(dim=5)  # Squeeze out the last dimension.\n",
    "print('x.shape: {}'.format(x.shape))  # Shape is changed in place.\n",
    "x.squeeze_(dim=-3)  # Squeeze out the third dimension (index `2`)\n",
    "print('x.shape: {}'.format(x.shape))  # Shape is changed in place.\n",
    "# Intrusive shape changes.\n",
    "print('*'*79)\n",
    "x = torch.randint(low=0, high=10, size=(3, 4))\n",
    "print('x: \\n{}'.format(x))\n",
    "x.resize_(2, 3)  # Takes first 6 elements from `x` and arranges them in shape `(2, 3)`.\n",
    "print('x resized in place: \\n{}'.format(x))\n",
    "y = torch.randint(low=0, high=10, size=(3, 4))\n",
    "print('y: \\n{}'.format(y))\n",
    "y.resize_(4, 5)  # Takes first 3*4=12 elements from `y` and appends garbage to make `(4, 5)` shaped tensor.\n",
    "print('y resized in place: \\n{}'.format(y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_np: \n",
      "[[7 8 4 2]\n",
      " [6 5 3 6]\n",
      " [5 3 8 7]]\n",
      "x_np type: int64\n",
      "x_torch: \n",
      "tensor([[7, 8, 4, 2],\n",
      "        [6, 5, 3, 6],\n",
      "        [5, 3, 8, 7]])\n",
      "x_torch type: torch.int64\n",
      "x_np: \n",
      "[[1000    8    4    2]\n",
      " [   6    5    3    6]\n",
      " [   5    3    8    7]]\n",
      "x_torch: \n",
      "tensor([[1000,    8,    4,    2],\n",
      "        [   6,    5,    3,    6],\n",
      "        [   5,    3,    8,    7]])\n",
      "x_np: \n",
      "[[1000    8    4    2]\n",
      " [   6    5    3    6]\n",
      " [   5    3    8 2000]]\n",
      "x_torch: \n",
      "tensor([[1000,    8,    4,    2],\n",
      "        [   6,    5,    3,    6],\n",
      "        [   5,    3,    8, 2000]])\n",
      "*******************************************************************************\n",
      "x_torch: \n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "x_torch type: torch.float32\n",
      "x_np: \n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "x_np type: float32\n",
      "x_np: \n",
      "[[1000.    2.]\n",
      " [   3.    4.]]\n",
      "x_torch: \n",
      "tensor([[1000.,    2.],\n",
      "        [   3.,    4.]])\n",
      "x_np: \n",
      "[[1000.    2.]\n",
      " [   3. 2000.]]\n",
      "x_torch: \n",
      "tensor([[1000.,    2.],\n",
      "        [   3., 2000.]])\n",
      "*******************************************************************************\n",
      "x_np: \n",
      "[[5 5 7 1]\n",
      " [4 9 9 7]\n",
      " [8 3 8 4]]\n",
      "x_np type: int64\n",
      "x_torch: \n",
      "tensor([[5, 5, 7, 1],\n",
      "        [4, 9, 9, 7],\n",
      "        [8, 3, 8, 4]])\n",
      "x_torch type: torch.int64\n",
      "x_np: \n",
      "[[1000    5    7    1]\n",
      " [   4    9    9    7]\n",
      " [   8    3    8    4]]\n",
      "x_torch: \n",
      "tensor([[5, 5, 7, 1],\n",
      "        [4, 9, 9, 7],\n",
      "        [8, 3, 8, 4]])\n",
      "x_np: \n",
      "[[1000    5    7    1]\n",
      " [   4    9    9    7]\n",
      " [   8    3    8    4]]\n",
      "x_torch: \n",
      "tensor([[   5,    5,    7,    1],\n",
      "        [   4,    9,    9,    7],\n",
      "        [   8,    3,    8, 2000]])\n",
      "*******************************************************************************\n",
      "x_torch: \n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "x_torch type: torch.float32\n",
      "x_np: \n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "x_np type: float32\n",
      "x_np: \n",
      "[[1000.    2.]\n",
      " [   3.    4.]]\n",
      "x_torch: \n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "x_np: \n",
      "[[1000.    2.]\n",
      " [   3.    4.]]\n",
      "x_torch: \n",
      "tensor([[1.0000e+00, 2.0000e+00],\n",
      "        [3.0000e+00, 2.0000e+03]])\n"
     ]
    }
   ],
   "source": [
    "# To-and-from numpy.\n",
    "x_np = np.random.randint(low=0, high=10, size=(3, 4))\n",
    "print('x_np: \\n{}\\nx_np type: {}'.format(x_np, x_np.dtype))\n",
    "x_torch = torch.from_numpy(x_np)  # This preserves the type.\n",
    "print('x_torch: \\n{}\\nx_torch type: {}'.format(x_torch, x_torch.dtype))\n",
    "x_np[0, 0] = 1000\n",
    "print('x_np: \\n{}\\nx_torch: \\n{}'.format(x_np, x_torch))  # They share the same underlying memory!\n",
    "x_torch[-1, -1] = 2000\n",
    "print('x_np: \\n{}\\nx_torch: \\n{}'.format(x_np, x_torch))  # They share the same underlying memory!\n",
    "print('*'*79)\n",
    "x_torch = torch.tensor(data=((1, 2,), (3, 4)), dtype=torch.float32)\n",
    "x_np = x_torch.numpy()\n",
    "print('x_torch: \\n{}\\nx_torch type: {}'.format(x_torch, x_torch.dtype))\n",
    "print('x_np: \\n{}\\nx_np type: {}'.format(x_np, x_np.dtype))\n",
    "x_np[0, 0] = 1000\n",
    "print('x_np: \\n{}\\nx_torch: \\n{}'.format(x_np, x_torch))  # They share the same underlying memory!\n",
    "x_torch[-1, -1] = 2000\n",
    "print('x_np: \\n{}\\nx_torch: \\n{}'.format(x_np, x_torch))  # They share the same underlying memory!\n",
    "# If we want to change the data locations, use `.clone()`\n",
    "print('*'*79)\n",
    "x_np = np.random.randint(low=0, high=10, size=(3, 4))\n",
    "print('x_np: \\n{}\\nx_np type: {}'.format(x_np, x_np.dtype))\n",
    "x_torch = torch.from_numpy(x_np).clone()  # This preserves the type.\n",
    "print('x_torch: \\n{}\\nx_torch type: {}'.format(x_torch, x_torch.dtype))\n",
    "x_np[0, 0] = 1000\n",
    "print('x_np: \\n{}\\nx_torch: \\n{}'.format(x_np, x_torch))  # They DO NOT share the same underlying memory!\n",
    "x_torch[-1, -1] = 2000\n",
    "print('x_np: \\n{}\\nx_torch: \\n{}'.format(x_np, x_torch))  # They DO NOT share the same underlying memory!\n",
    "print('*'*79)\n",
    "x_torch = torch.tensor(data=((1, 2,), (3, 4)), dtype=torch.float32)\n",
    "x_np = x_torch.clone().numpy()\n",
    "print('x_torch: \\n{}\\nx_torch type: {}'.format(x_torch, x_torch.dtype))\n",
    "print('x_np: \\n{}\\nx_np type: {}'.format(x_np, x_np.dtype))\n",
    "x_np[0, 0] = 1000\n",
    "print('x_np: \\n{}\\nx_torch: \\n{}'.format(x_np, x_torch))  # They share the same underlying memory!\n",
    "x_torch[-1, -1] = 2000\n",
    "print('x_np: \\n{}\\nx_torch: \\n{}'.format(x_np, x_torch))  # They share the same underlying memory!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}