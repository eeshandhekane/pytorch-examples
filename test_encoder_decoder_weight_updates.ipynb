{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "IN_DIM = 5\n",
    "HIDDEN_DIM = 3\n",
    "OUT_DIM = 2\n",
    "NUM_EPOCHS = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Set seeds.\n",
    "torch.manual_seed(43865)\n",
    "random.seed(43865)\n",
    "np.random.seed(43865)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder state:\n",
      "tensor([[-0.4795, -0.8184, -1.7956, -0.7481,  0.4085],\n",
      "        [ 0.6789,  0.0540, -0.5776,  0.4270, -0.0400],\n",
      "        [ 0.8674, -0.5720, -1.3464, -0.0660,  1.0107]])\n",
      "decoder state:\n",
      "tensor([[-0.6348,  0.1551, -0.2081],\n",
      "        [-1.1093,  0.7112, -1.0249]])\n"
     ]
    }
   ],
   "source": [
    "encoder_state_dict = OrderedDict()\n",
    "decoder_state_dict = OrderedDict()\n",
    "encoder_state_dict['weight'] = torch.randn(HIDDEN_DIM, IN_DIM)\n",
    "decoder_state_dict['weight'] = torch.randn(OUT_DIM, HIDDEN_DIM)\n",
    "print('encoder state:\\n{}'.format(encoder_state_dict['weight']))\n",
    "print('decoder state:\\n{}'.format(decoder_state_dict['weight']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight state:\n",
      "tensor([[-0.4795, -0.8184, -1.7956, -0.7481,  0.4085],\n",
      "        [ 0.6789,  0.0540, -0.5776,  0.4270, -0.0400],\n",
      "        [ 0.8674, -0.5720, -1.3464, -0.0660,  1.0107]])\n",
      "fc2.weight state:\n",
      "tensor([[-0.6348,  0.1551, -0.2081],\n",
      "        [-1.1093,  0.7112, -1.0249]])\n"
     ]
    }
   ],
   "source": [
    "# Set seeds.\n",
    "torch.manual_seed(43865)\n",
    "random.seed(43865)\n",
    "np.random.seed(43865)\n",
    "model_state_dict = OrderedDict()\n",
    "model_state_dict['fc1.weight'] = torch.randn(HIDDEN_DIM, IN_DIM)\n",
    "model_state_dict['fc2.weight'] = torch.randn(OUT_DIM, HIDDEN_DIM)\n",
    "for param, value in model_state_dict.items():\n",
    "    print('{} state:\\n{}'.format(param, value))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder state dict:\n",
      "odict_keys(['weight'])\n",
      "decoder state dict:\n",
      "odict_keys(['weight'])\n",
      "model state dict:\n",
      "odict_keys(['fc1.weight', 'fc2.weight'])\n"
     ]
    }
   ],
   "source": [
    "# Define encoder, decoder, and complete model.\n",
    "encoder = nn.Linear(\n",
    "    in_features=IN_DIM, out_features=HIDDEN_DIM, bias=False\n",
    ")\n",
    "decoder = nn.Linear(\n",
    "    in_features=HIDDEN_DIM, out_features=OUT_DIM, bias=False\n",
    ")\n",
    "\n",
    "class Model(nn.Module):\n",
    "    r\"\"\"Basic model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        r\"\"\"The initializer.\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=IN_DIM, out_features=HIDDEN_DIM, bias=False\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=HIDDEN_DIM, out_features=OUT_DIM, bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Implements the forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x:\n",
    "            Input tensor.\n",
    "            SHAPE: [B, input_dim].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        feature (implicit):\n",
    "            The tensor of features of the input.\n",
    "            SHAPE: [B, output_dim].\n",
    "        \"\"\"\n",
    "        return self.fc2(self.fc1(x))\n",
    "\n",
    "model = Model()\n",
    "\n",
    "print('encoder state dict:\\n{}'.format(encoder.state_dict().keys()))\n",
    "print('decoder state dict:\\n{}'.format(decoder.state_dict().keys()))\n",
    "print('model state dict:\\n{}'.format(model.state_dict().keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Set the states for all the models.\n",
    "_ = encoder.load_state_dict(state_dict=encoder_state_dict)\n",
    "_ = decoder.load_state_dict(state_dict=decoder_state_dict)\n",
    "_ = model.load_state_dict(state_dict=model_state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "encoder_optim = optim.SGD(params=encoder.parameters(), lr=1e-3)\n",
    "decoder_optim = optim.SGD(params=decoder.parameters(), lr=1e-3)\n",
    "model_optim = optim.SGD(params=model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t\tloss: 8.983654022216797\n",
      "epoch: 1\t\tloss: 8.795275688171387\n",
      "epoch: 2\t\tloss: 8.612491607666016\n",
      "epoch: 3\t\tloss: 8.435084342956543\n",
      "epoch: 4\t\tloss: 8.262846946716309\n",
      "epoch: 5\t\tloss: 8.09557819366455\n",
      "epoch: 6\t\tloss: 7.933091163635254\n",
      "epoch: 7\t\tloss: 7.775203704833984\n",
      "epoch: 8\t\tloss: 7.621746063232422\n",
      "epoch: 9\t\tloss: 7.472555160522461\n",
      "epoch: 10\t\tloss: 7.327475070953369\n",
      "epoch: 11\t\tloss: 7.186354160308838\n",
      "epoch: 12\t\tloss: 7.049053192138672\n",
      "epoch: 13\t\tloss: 6.915436267852783\n",
      "epoch: 14\t\tloss: 6.785372734069824\n",
      "epoch: 15\t\tloss: 6.6587395668029785\n",
      "epoch: 16\t\tloss: 6.5354180335998535\n",
      "epoch: 17\t\tloss: 6.415295124053955\n",
      "epoch: 18\t\tloss: 6.298261642456055\n",
      "epoch: 19\t\tloss: 6.184215545654297\n",
      "epoch: 20\t\tloss: 6.073055267333984\n",
      "epoch: 21\t\tloss: 5.964685440063477\n",
      "epoch: 22\t\tloss: 5.8590168952941895\n",
      "epoch: 23\t\tloss: 5.755959510803223\n",
      "epoch: 24\t\tloss: 5.655431270599365\n",
      "epoch: 25\t\tloss: 5.557348728179932\n",
      "epoch: 26\t\tloss: 5.4616379737854\n",
      "epoch: 27\t\tloss: 5.368220329284668\n",
      "epoch: 28\t\tloss: 5.277028560638428\n",
      "epoch: 29\t\tloss: 5.187990188598633\n",
      "epoch: 30\t\tloss: 5.101042747497559\n",
      "epoch: 31\t\tloss: 5.016120910644531\n",
      "epoch: 32\t\tloss: 4.933163166046143\n",
      "epoch: 33\t\tloss: 4.852111339569092\n",
      "epoch: 34\t\tloss: 4.772909164428711\n",
      "epoch: 35\t\tloss: 4.695501327514648\n",
      "epoch: 36\t\tloss: 4.619835376739502\n",
      "epoch: 37\t\tloss: 4.545860767364502\n",
      "epoch: 38\t\tloss: 4.473529815673828\n",
      "epoch: 39\t\tloss: 4.402793884277344\n",
      "epoch: 40\t\tloss: 4.333609104156494\n",
      "epoch: 41\t\tloss: 4.265930652618408\n",
      "epoch: 42\t\tloss: 4.199716091156006\n",
      "epoch: 43\t\tloss: 4.134926795959473\n",
      "epoch: 44\t\tloss: 4.071521282196045\n",
      "epoch: 45\t\tloss: 4.009462833404541\n",
      "epoch: 46\t\tloss: 3.9487130641937256\n",
      "epoch: 47\t\tloss: 3.8892393112182617\n",
      "epoch: 48\t\tloss: 3.8310048580169678\n",
      "epoch: 49\t\tloss: 3.7739784717559814\n",
      "epoch: 50\t\tloss: 3.7181270122528076\n",
      "epoch: 51\t\tloss: 3.6634202003479004\n",
      "epoch: 52\t\tloss: 3.6098265647888184\n",
      "epoch: 53\t\tloss: 3.5573203563690186\n",
      "epoch: 54\t\tloss: 3.5058701038360596\n",
      "epoch: 55\t\tloss: 3.4554507732391357\n",
      "epoch: 56\t\tloss: 3.4060354232788086\n",
      "epoch: 57\t\tloss: 3.3575985431671143\n",
      "epoch: 58\t\tloss: 3.3101160526275635\n",
      "epoch: 59\t\tloss: 3.2635645866394043\n",
      "epoch: 60\t\tloss: 3.217918872833252\n",
      "epoch: 61\t\tloss: 3.1731584072113037\n",
      "epoch: 62\t\tloss: 3.1292612552642822\n",
      "epoch: 63\t\tloss: 3.0862057209014893\n",
      "epoch: 64\t\tloss: 3.0439717769622803\n",
      "epoch: 65\t\tloss: 3.0025393962860107\n",
      "epoch: 66\t\tloss: 2.9618895053863525\n",
      "epoch: 67\t\tloss: 2.922003746032715\n",
      "epoch: 68\t\tloss: 2.8828632831573486\n",
      "epoch: 69\t\tloss: 2.844451427459717\n",
      "epoch: 70\t\tloss: 2.8067502975463867\n",
      "epoch: 71\t\tloss: 2.7697439193725586\n",
      "epoch: 72\t\tloss: 2.7334163188934326\n",
      "epoch: 73\t\tloss: 2.697751760482788\n",
      "epoch: 74\t\tloss: 2.662734270095825\n",
      "epoch: 75\t\tloss: 2.628350019454956\n",
      "epoch: 76\t\tloss: 2.5945842266082764\n",
      "epoch: 77\t\tloss: 2.5614235401153564\n",
      "epoch: 78\t\tloss: 2.528853416442871\n",
      "epoch: 79\t\tloss: 2.496861219406128\n",
      "epoch: 80\t\tloss: 2.4654347896575928\n",
      "epoch: 81\t\tloss: 2.4345602989196777\n",
      "epoch: 82\t\tloss: 2.4042270183563232\n",
      "epoch: 83\t\tloss: 2.3744218349456787\n",
      "epoch: 84\t\tloss: 2.3451342582702637\n",
      "epoch: 85\t\tloss: 2.3163528442382812\n",
      "epoch: 86\t\tloss: 2.2880666255950928\n",
      "epoch: 87\t\tloss: 2.2602648735046387\n",
      "epoch: 88\t\tloss: 2.2329368591308594\n",
      "epoch: 89\t\tloss: 2.2060742378234863\n",
      "epoch: 90\t\tloss: 2.1796653270721436\n",
      "epoch: 91\t\tloss: 2.1537017822265625\n",
      "epoch: 92\t\tloss: 2.128173589706421\n",
      "epoch: 93\t\tloss: 2.103071689605713\n",
      "epoch: 94\t\tloss: 2.0783884525299072\n",
      "epoch: 95\t\tloss: 2.0541138648986816\n",
      "epoch: 96\t\tloss: 2.030240297317505\n",
      "epoch: 97\t\tloss: 2.0067591667175293\n",
      "epoch: 98\t\tloss: 1.9836623668670654\n",
      "epoch: 99\t\tloss: 1.9609427452087402\n"
     ]
    }
   ],
   "source": [
    "# Encoder-decoder training.\n",
    "torch.manual_seed(43865)\n",
    "random.seed(43865)\n",
    "np.random.seed(43865)\n",
    "# Create data.\n",
    "x = torch.randn(size=(BATCH_SIZE, IN_DIM))\n",
    "y = torch.randn(size=(BATCH_SIZE, OUT_DIM))\n",
    "# Set to training mode.\n",
    "encoder = encoder.train()\n",
    "decoder = decoder.train()\n",
    "encoder_decoder_loss_list = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    encoder_optim.zero_grad()\n",
    "    decoder_optim.zero_grad()\n",
    "    y_pred = decoder(encoder(x))\n",
    "    loss = torch.mean((y_pred - y)**2)\n",
    "    loss_value = loss.detach().numpy()\n",
    "    print('epoch: {}\\t\\tloss: {}'.format(epoch, loss_value))\n",
    "    encoder_decoder_loss_list.append(loss_value)\n",
    "    loss.backward()\n",
    "    encoder_optim.step()\n",
    "    decoder_optim.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t\tloss: 8.983654022216797\n",
      "epoch: 1\t\tloss: 8.795275688171387\n",
      "epoch: 2\t\tloss: 8.612491607666016\n",
      "epoch: 3\t\tloss: 8.435084342956543\n",
      "epoch: 4\t\tloss: 8.262846946716309\n",
      "epoch: 5\t\tloss: 8.09557819366455\n",
      "epoch: 6\t\tloss: 7.933091163635254\n",
      "epoch: 7\t\tloss: 7.775203704833984\n",
      "epoch: 8\t\tloss: 7.621746063232422\n",
      "epoch: 9\t\tloss: 7.472555160522461\n",
      "epoch: 10\t\tloss: 7.327475070953369\n",
      "epoch: 11\t\tloss: 7.186354160308838\n",
      "epoch: 12\t\tloss: 7.049053192138672\n",
      "epoch: 13\t\tloss: 6.915436267852783\n",
      "epoch: 14\t\tloss: 6.785372734069824\n",
      "epoch: 15\t\tloss: 6.6587395668029785\n",
      "epoch: 16\t\tloss: 6.5354180335998535\n",
      "epoch: 17\t\tloss: 6.415295124053955\n",
      "epoch: 18\t\tloss: 6.298261642456055\n",
      "epoch: 19\t\tloss: 6.184215545654297\n",
      "epoch: 20\t\tloss: 6.073055267333984\n",
      "epoch: 21\t\tloss: 5.964685440063477\n",
      "epoch: 22\t\tloss: 5.8590168952941895\n",
      "epoch: 23\t\tloss: 5.755959510803223\n",
      "epoch: 24\t\tloss: 5.655431270599365\n",
      "epoch: 25\t\tloss: 5.557348728179932\n",
      "epoch: 26\t\tloss: 5.4616379737854\n",
      "epoch: 27\t\tloss: 5.368220329284668\n",
      "epoch: 28\t\tloss: 5.277028560638428\n",
      "epoch: 29\t\tloss: 5.187990188598633\n",
      "epoch: 30\t\tloss: 5.101042747497559\n",
      "epoch: 31\t\tloss: 5.016120910644531\n",
      "epoch: 32\t\tloss: 4.933163166046143\n",
      "epoch: 33\t\tloss: 4.852111339569092\n",
      "epoch: 34\t\tloss: 4.772909164428711\n",
      "epoch: 35\t\tloss: 4.695501327514648\n",
      "epoch: 36\t\tloss: 4.619835376739502\n",
      "epoch: 37\t\tloss: 4.545860767364502\n",
      "epoch: 38\t\tloss: 4.473529815673828\n",
      "epoch: 39\t\tloss: 4.402793884277344\n",
      "epoch: 40\t\tloss: 4.333609104156494\n",
      "epoch: 41\t\tloss: 4.265930652618408\n",
      "epoch: 42\t\tloss: 4.199716091156006\n",
      "epoch: 43\t\tloss: 4.134926795959473\n",
      "epoch: 44\t\tloss: 4.071521282196045\n",
      "epoch: 45\t\tloss: 4.009462833404541\n",
      "epoch: 46\t\tloss: 3.9487130641937256\n",
      "epoch: 47\t\tloss: 3.8892393112182617\n",
      "epoch: 48\t\tloss: 3.8310048580169678\n",
      "epoch: 49\t\tloss: 3.7739784717559814\n",
      "epoch: 50\t\tloss: 3.7181270122528076\n",
      "epoch: 51\t\tloss: 3.6634202003479004\n",
      "epoch: 52\t\tloss: 3.6098265647888184\n",
      "epoch: 53\t\tloss: 3.5573203563690186\n",
      "epoch: 54\t\tloss: 3.5058701038360596\n",
      "epoch: 55\t\tloss: 3.4554507732391357\n",
      "epoch: 56\t\tloss: 3.4060354232788086\n",
      "epoch: 57\t\tloss: 3.3575985431671143\n",
      "epoch: 58\t\tloss: 3.3101160526275635\n",
      "epoch: 59\t\tloss: 3.2635645866394043\n",
      "epoch: 60\t\tloss: 3.217918872833252\n",
      "epoch: 61\t\tloss: 3.1731584072113037\n",
      "epoch: 62\t\tloss: 3.1292612552642822\n",
      "epoch: 63\t\tloss: 3.0862057209014893\n",
      "epoch: 64\t\tloss: 3.0439717769622803\n",
      "epoch: 65\t\tloss: 3.0025393962860107\n",
      "epoch: 66\t\tloss: 2.9618895053863525\n",
      "epoch: 67\t\tloss: 2.922003746032715\n",
      "epoch: 68\t\tloss: 2.8828632831573486\n",
      "epoch: 69\t\tloss: 2.844451427459717\n",
      "epoch: 70\t\tloss: 2.8067502975463867\n",
      "epoch: 71\t\tloss: 2.7697439193725586\n",
      "epoch: 72\t\tloss: 2.7334163188934326\n",
      "epoch: 73\t\tloss: 2.697751760482788\n",
      "epoch: 74\t\tloss: 2.662734270095825\n",
      "epoch: 75\t\tloss: 2.628350019454956\n",
      "epoch: 76\t\tloss: 2.5945842266082764\n",
      "epoch: 77\t\tloss: 2.5614235401153564\n",
      "epoch: 78\t\tloss: 2.528853416442871\n",
      "epoch: 79\t\tloss: 2.496861219406128\n",
      "epoch: 80\t\tloss: 2.4654347896575928\n",
      "epoch: 81\t\tloss: 2.4345602989196777\n",
      "epoch: 82\t\tloss: 2.4042270183563232\n",
      "epoch: 83\t\tloss: 2.3744218349456787\n",
      "epoch: 84\t\tloss: 2.3451342582702637\n",
      "epoch: 85\t\tloss: 2.3163528442382812\n",
      "epoch: 86\t\tloss: 2.2880666255950928\n",
      "epoch: 87\t\tloss: 2.2602648735046387\n",
      "epoch: 88\t\tloss: 2.2329368591308594\n",
      "epoch: 89\t\tloss: 2.2060742378234863\n",
      "epoch: 90\t\tloss: 2.1796653270721436\n",
      "epoch: 91\t\tloss: 2.1537017822265625\n",
      "epoch: 92\t\tloss: 2.128173589706421\n",
      "epoch: 93\t\tloss: 2.103071689605713\n",
      "epoch: 94\t\tloss: 2.0783884525299072\n",
      "epoch: 95\t\tloss: 2.0541138648986816\n",
      "epoch: 96\t\tloss: 2.030240297317505\n",
      "epoch: 97\t\tloss: 2.0067591667175293\n",
      "epoch: 98\t\tloss: 1.9836623668670654\n",
      "epoch: 99\t\tloss: 1.9609427452087402\n"
     ]
    }
   ],
   "source": [
    "# Encoder-decoder training.\n",
    "torch.manual_seed(43865)\n",
    "random.seed(43865)\n",
    "np.random.seed(43865)\n",
    "# Create data.\n",
    "x_model = torch.randn(size=(BATCH_SIZE, IN_DIM))\n",
    "y_model = torch.randn(size=(BATCH_SIZE, OUT_DIM))\n",
    "# Set to training mode.\n",
    "model = model.train()\n",
    "model_loss_list = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model_optim.zero_grad()\n",
    "    y_pred_model = model(x_model)\n",
    "    loss_model = torch.mean((y_pred_model - y_model)**2)\n",
    "    loss_model_value = loss_model.detach().numpy()\n",
    "    print('epoch: {}\\t\\tloss: {}'.format(epoch, loss_model_value))\n",
    "    model_loss_list.append(loss_model_value)\n",
    "    loss_model.backward()\n",
    "    model_optim.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data created in both cases is the same: True\n",
      "losses from both the cases match: True\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks.\n",
    "print('data created in both cases is the same: {}'.format(\n",
    "    torch.all(torch.eq(x, x_model)) and torch.all(torch.eq(y, y_model))\n",
    "))\n",
    "print('losses from both the cases match: {}'.format(\n",
    "    len(encoder_decoder_loss_list) == len(model_loss_list) and \\\n",
    "    all([\n",
    "        encoder_decoder_loss_list[idx] == model_loss_list[idx] \\\n",
    "            for idx in range(len(encoder_decoder_loss_list))\n",
    "    ])\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}